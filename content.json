{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"John Doe","url":"http://yoursite.com"},"pages":[{"title":"分类","date":"2019-01-11T03:01:41.796Z","updated":"2019-01-02T07:50:11.790Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"书单","date":"2019-01-11T02:58:06.971Z","updated":"2019-01-02T07:50:11.790Z","comments":false,"path":"books/index.html","permalink":"http://yoursite.com/books/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2019-01-18T07:01:24.126Z","updated":"2019-01-02T07:50:11.790Z","comments":true,"path":"links/index.html","permalink":"http://yoursite.com/links/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-01-18T07:23:39.338Z","updated":"2019-01-02T07:50:11.790Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"关于","date":"2019-01-18T07:23:07.452Z","updated":"2019-01-18T07:23:07.452Z","comments":false,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"123456789101112131415161718192021222324252627282930&#123; name: 'znn' age: 24, gender: '男', profession: 'Web Developer &amp; Designer', experience: '4年', github: 'https://github.com/znnspace', blog: 'http://blog.znnspace.com', email: 'znnspace@foxmail.com', description: '致力于网站建设与前端用户体验设计', skills: [ ['Html', 'Javascript', 'jQuery', 'CSS', 'ES6', 'Node'], ['Webpack', 'Gulp'], ['Less','Sass'], ['Git', 'SVN'], ['Vue'], ['Bootstrap', 'SUI Mobile', 'light7'], ['WordPress', 'OpenCart'], ['平面设计'] ], devTools: [ ['Sublime Text', 'Visual Studio Code', 'Notepad++'], ['Chrome DevTools', 'Fiddler'], ['SourceTree', 'TortoiseSVN'], ['SwitchHosts'], ['Navicat', 'XAMPP'], ] &#125;"},{"title":"Repositories","date":"2019-01-18T07:25:43.238Z","updated":"2019-01-02T07:50:11.790Z","comments":false,"path":"repository/index.html","permalink":"http://yoursite.com/repository/index.html","excerpt":"","text":""}],"posts":[{"title":"分布式锁之Redis实现","slug":"分布式锁之Redis实现","date":"2019-03-04T08:45:27.633Z","updated":"2019-03-08T07:57:54.039Z","comments":true,"path":"2019/03/04/分布式锁之Redis实现/","link":"","permalink":"http://yoursite.com/2019/03/04/分布式锁之Redis实现/","excerpt":"","text":"在Java中，关于锁我想大家都很熟悉。在并发编程中，我们通过锁，来避免由于竞争而造成的数据不一致问题。通常，我们以synchronized 、Lock来使用它。 但是Java中的锁，只能保证在同一个JVM进程内中执行。如果在分布式集群环境下呢？ 一、分布式锁分布式锁，是一种思想，它的实现方式有很多。比如，我们将沙滩当做分布式锁的组件，那么它看起来应该是这样的： 加锁 在沙滩上踩一脚，留下自己的脚印，就对应了加锁操作。其他进程或者线程，看到沙滩上已经有脚印，证明锁已被别人持有，则等待。 解锁 把脚印从沙滩上抹去，就是解锁的过程。 锁超时 为了避免死锁，我们可以设置一阵风，在单位时间后刮起，将脚印自动抹去。 分布式锁的实现有很多，比如基于数据库、memcached、Redis、系统文件、zookeeper等。它们的核心的理念跟上面的过程大致相同。 二、redis我们先来看如何通过单节点Redis实现一个简单的分布式锁。 1、加锁加锁实际上就是在redis中，给Key键设置一个值，为避免死锁，并给定一个过期时间。 1SET lock_key random_value NX PX 5000 值得注意的是： random_value 是客户端生成的唯一的字符串。 NX 代表只在键不存在时，才对键进行设置操作。 PX 5000 设置键的过期时间为5000毫秒。 这样，如果上面的命令执行成功，则证明客户端获取到了锁。 2、解锁解锁的过程就是将Key键删除。但也不能乱删，不能说客户端1的请求将客户端2的锁给删除掉。这时候random_value的作用就体现出来。 为了保证解锁操作的原子性，我们用LUA脚本完成这一操作。先判断当前锁的字符串是否与传入的值相等，是的话就删除Key，解锁成功。 12345if redis.call(&apos;get&apos;,KEYS[1]) == ARGV[1] then return redis.call(&apos;del&apos;,KEYS[1]) else return 0 end 3、实现首先，我们在pom文件中，引入Jedis。在这里，笔者用的是最新版本，注意由于版本的不同，API可能有所差异。 12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt;&lt;/dependency&gt; 加锁的过程很简单，就是通过SET指令来设置值，成功则返回；否则就循环等待，在timeout时间内仍未获取到锁，则获取失败。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Servicepublic class RedisLock &#123; Logger logger = LoggerFactory.getLogger(this.getClass()); private String lock_key = &quot;redis_lock&quot;; //锁键 protected long internalLockLeaseTime = 30000;//锁过期时间 private long timeout = 999999; //获取锁的超时时间 //SET命令的参数 SetParams params = SetParams.setParams().nx().px(internalLockLeaseTime); @Autowired JedisPool jedisPool; /** * 加锁 * @param id * @return */ public boolean lock(String id)&#123; Jedis jedis = jedisPool.getResource(); Long start = System.currentTimeMillis(); try&#123; for(;;)&#123; //SET命令返回OK ，则证明获取锁成功 String lock = jedis.set(lock_key, id, params); if(&quot;OK&quot;.equals(lock))&#123; return true; &#125; //否则循环等待，在timeout时间内仍未获取到锁，则获取失败 long l = System.currentTimeMillis() - start; if (l&gt;=timeout) &#123; return false; &#125; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;finally &#123; jedis.close(); &#125; &#125;&#125; 解锁我们通过jedis.eval来执行一段LUA就可以。将锁的Key键和生成的字符串当做参数传进来。 123456789101112131415161718192021222324/** * 解锁 * @param id * @return */ public boolean unlock(String id)&#123; Jedis jedis = jedisPool.getResource(); String script = &quot;if redis.call(&apos;get&apos;,KEYS[1]) == ARGV[1] then&quot; + &quot; return redis.call(&apos;del&apos;,KEYS[1]) &quot; + &quot;else&quot; + &quot; return 0 &quot; + &quot;end&quot;; try &#123; Object result = jedis.eval(script, Collections.singletonList(lock_key), Collections.singletonList(id)); if(&quot;1&quot;.equals(result.toString()))&#123; return true; &#125; return false; &#125;finally &#123; jedis.close(); &#125; &#125; 最后，我们可以在多线程环境下测试一下。我们开启1000个线程，对count进行累加。调用的时候，关键是唯一字符串的生成。这里，笔者使用的是Snowflake算法。 12345678910111213141516171819202122232425262728293031323334353637@Controllerpublic class IndexController &#123; @Autowired RedisLock redisLock; int count = 0; @RequestMapping(&quot;/index&quot;) @ResponseBody public String index() throws InterruptedException &#123; int clientcount =1000; CountDownLatch countDownLatch = new CountDownLatch(clientcount); ExecutorService executorService = Executors.newFixedThreadPool(clientcount); long start = System.currentTimeMillis(); for (int i = 0;i&lt;clientcount;i++)&#123; executorService.execute(() -&gt; &#123; //通过Snowflake算法获取唯一的ID字符串 String id = IdUtil.getId(); try &#123; redisLock.lock(id); count++; &#125;finally &#123; redisLock.unlock(id); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); long end = System.currentTimeMillis(); logger.info(&quot;执行线程数:&#123;&#125;,总耗时:&#123;&#125;,count数为:&#123;&#125;&quot;,clientcount,end-start,count); return &quot;Hello&quot;; &#125;&#125; 至此，单节点Redis的分布式锁的实现就已经完成了。比较简单，但是问题也比较大，最重要的一点是，锁不具有可重入性。 三、redisson Redisson是架设在Redis基础上的一个Java驻内存数据网格（In-Memory Data Grid）。充分的利用了Redis键值数据库提供的一系列优势，基于Java实用工具包中常用接口，为使用者提供了一系列具有分布式特性的常用工具类。使得原本作为协调单机多线程并发程序的工具包获得了协调分布式多机多线程并发系统的能力，大大降低了设计和研发大规模分布式系统的难度。同时结合各富特色的分布式服务，更进一步简化了分布式环境中程序相互之间的协作。 相对于Jedis而言，Redisson强大的一批。当然了，随之而来的就是它的复杂性。它里面也实现了分布式锁，而且包含多种类型的锁，更多请参阅分布式锁和同步器 1、可重入锁上面我们自己实现的Redis分布式锁，其实不具有可重入性。那么下面我们先来看看Redisson中如何调用可重入锁。 在这里，笔者使用的是它的最新版本，3.10.1。 12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.10.1&lt;/version&gt;&lt;/dependency&gt; 首先，通过配置获取RedissonClient客户端的实例，然后getLock获取锁的实例，进行操作即可。 123456789101112131415public static void main(String[] args) &#123; Config config = new Config(); config.useSingleServer().setAddress(&quot;redis://127.0.0.1:6379&quot;); config.useSingleServer().setPassword(&quot;redis1234&quot;); final RedissonClient client = Redisson.create(config); RLock lock = client.getLock(&quot;lock1&quot;); try&#123; lock.lock(); &#125;finally&#123; lock.unlock(); &#125;&#125; 2、获取锁实例我们先来看RLock lock = client.getLock(&quot;lock1&quot;); 这句代码就是为了获取锁的实例，然后我们可以看到它返回的是一个RedissonLock对象。 1234public RLock getLock(String name) &#123; return new RedissonLock(connectionManager.getCommandExecutor(), name);&#125;复制代码 在RedissonLock构造方法中，主要初始化一些属性。 1234567891011public RedissonLock(CommandAsyncExecutor commandExecutor, String name) &#123; super(commandExecutor, name); //命令执行器 this.commandExecutor = commandExecutor; //UUID字符串 this.id = commandExecutor.getConnectionManager().getId(); //内部锁过期时间 this.internalLockLeaseTime = commandExecutor. getConnectionManager().getCfg().getLockWatchdogTimeout(); this.entryName = id + &quot;:&quot; + name;&#125; 3、加锁当我们调用lock方法，定位到lockInterruptibly。在这里，完成了加锁的逻辑。 1234567891011121314151617181920212223242526272829303132333435public void lockInterruptibly(long leaseTime, TimeUnit unit) throws InterruptedException &#123; //当前线程ID long threadId = Thread.currentThread().getId(); //尝试获取锁 Long ttl = tryAcquire(leaseTime, unit, threadId); // 如果ttl为空，则证明获取锁成功 if (ttl == null) &#123; return; &#125; //如果获取锁失败，则订阅到对应这个锁的channel RFuture&lt;RedissonLockEntry&gt; future = subscribe(threadId); commandExecutor.syncSubscription(future); try &#123; while (true) &#123; //再次尝试获取锁 ttl = tryAcquire(leaseTime, unit, threadId); //ttl为空，说明成功获取锁，返回 if (ttl == null) &#123; break; &#125; //ttl大于0 则等待ttl时间后继续尝试获取 if (ttl &gt;= 0) &#123; getEntry(threadId).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS); &#125; else &#123; getEntry(threadId).getLatch().acquire(); &#125; &#125; &#125; finally &#123; //取消对channel的订阅 unsubscribe(future, threadId); &#125; //get(lockAsync(leaseTime, unit));&#125; 如上代码，就是加锁的全过程。先调用tryAcquire来获取锁，如果返回值ttl为空，则证明加锁成功，返回；如果不为空，则证明加锁失败。这时候，它会订阅这个锁的Channel，等待锁释放的消息，然后重新尝试获取锁。流程如下： 获取锁 获取锁的过程是怎样的呢？接下来就要看tryAcquire方法。在这里，它有两种处理方式，一种是带有过期时间的锁，一种是不带过期时间的锁。 1234567891011121314151617181920212223242526272829private &lt;T&gt; RFuture&lt;Long&gt; tryAcquireAsync(long leaseTime, TimeUnit unit, final long threadId) &#123; //如果带有过期时间，则按照普通方式获取锁 if (leaseTime != -1) &#123; return tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG); &#125; //先按照30秒的过期时间来执行获取锁的方法 RFuture&lt;Long&gt; ttlRemainingFuture = tryLockInnerAsync( commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG); //如果还持有这个锁，则开启定时任务不断刷新该锁的过期时间 ttlRemainingFuture.addListener(new FutureListener&lt;Long&gt;() &#123; @Override public void operationComplete(Future&lt;Long&gt; future) throws Exception &#123; if (!future.isSuccess()) &#123; return; &#125; Long ttlRemaining = future.getNow(); // lock acquired if (ttlRemaining == null) &#123; scheduleExpirationRenewal(threadId); &#125; &#125; &#125;); return ttlRemainingFuture;&#125; 接着往下看，tryLockInnerAsync方法是真正执行获取锁的逻辑，它是一段LUA脚本代码。在这里，它使用的是hash数据结构。 123456789101112131415161718192021222324&lt;T&gt; RFuture&lt;T&gt; tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T&gt; command) &#123; //过期时间 internalLockLeaseTime = unit.toMillis(leaseTime); return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command, //如果锁不存在，则通过hset设置它的值，并设置过期时间 &quot;if (redis.call(&apos;exists&apos;, KEYS[1]) == 0) then &quot; + &quot;redis.call(&apos;hset&apos;, KEYS[1], ARGV[2], 1); &quot; + &quot;redis.call(&apos;pexpire&apos;, KEYS[1], ARGV[1]); &quot; + &quot;return nil; &quot; + &quot;end; &quot; + //如果锁已存在，并且锁的是当前线程，则通过hincrby给数值递增1 &quot;if (redis.call(&apos;hexists&apos;, KEYS[1], ARGV[2]) == 1) then &quot; + &quot;redis.call(&apos;hincrby&apos;, KEYS[1], ARGV[2], 1); &quot; + &quot;redis.call(&apos;pexpire&apos;, KEYS[1], ARGV[1]); &quot; + &quot;return nil; &quot; + &quot;end; &quot; + //如果锁已存在，但并非本线程，则返回过期时间ttl &quot;return redis.call(&apos;pttl&apos;, KEYS[1]);&quot;, Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId)); &#125; 这段LUA代码看起来并不复杂，有三个判断： 通过exists判断，如果锁不存在，则设置值和过期时间，加锁成功 通过hexists判断，如果锁已存在，并且锁的是当前线程，则证明是重入锁，加锁成功 如果锁已存在，但锁的不是当前线程，则证明有其他线程持有锁。返回当前锁的过期时间，加锁失败 加锁成功后，在redis的内存数据中，就有一条hash结构的数据。Key为锁的名称；field为随机字符串+线程ID；值为1。如果同一线程多次调用lock方法，值递增1。 123127.0.0.1:6379&gt; hgetall lock11) \"b5ae0be4-5623-45a5-8faa-ab7eb167ce87:1\"2) \"1\" 4、解锁我们通过调用unlock方法来解锁。 1234567891011121314151617181920212223242526272829303132333435public RFuture&lt;Void&gt; unlockAsync(final long threadId) &#123; final RPromise&lt;Void&gt; result = new RedissonPromise&lt;Void&gt;(); //解锁方法 RFuture&lt;Boolean&gt; future = unlockInnerAsync(threadId); future.addListener(new FutureListener&lt;Boolean&gt;() &#123; @Override public void operationComplete(Future&lt;Boolean&gt; future) throws Exception &#123; if (!future.isSuccess()) &#123; cancelExpirationRenewal(threadId); result.tryFailure(future.cause()); return; &#125; //获取返回值 Boolean opStatus = future.getNow(); //如果返回空，则证明解锁的线程和当前锁不是同一个线程，抛出异常 if (opStatus == null) &#123; IllegalMonitorStateException cause = new IllegalMonitorStateException(&quot; attempt to unlock lock, not locked by current thread by node id: &quot; + id + &quot; thread-id: &quot; + threadId); result.tryFailure(cause); return; &#125; //解锁成功，取消刷新过期时间的那个定时任务 if (opStatus) &#123; cancelExpirationRenewal(null); &#125; result.trySuccess(null); &#125; &#125;); return result;&#125; 然后我们再看unlockInnerAsync方法。这里也是一段LUA脚本代码。 1234567891011121314151617181920212223242526272829protected RFuture&lt;Boolean&gt; unlockInnerAsync(long threadId) &#123; return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, EVAL, //如果锁已经不存在， 发布锁释放的消息 &quot;if (redis.call(&apos;exists&apos;, KEYS[1]) == 0) then &quot; + &quot;redis.call(&apos;publish&apos;, KEYS[2], ARGV[1]); &quot; + &quot;return 1; &quot; + &quot;end;&quot; + //如果释放锁的线程和已存在锁的线程不是同一个线程，返回null &quot;if (redis.call(&apos;hexists&apos;, KEYS[1], ARGV[3]) == 0) then &quot; + &quot;return nil;&quot; + &quot;end; &quot; + //通过hincrby递减1的方式，释放一次锁 //若剩余次数大于0 ，则刷新过期时间 &quot;local counter = redis.call(&apos;hincrby&apos;, KEYS[1], ARGV[3], -1); &quot; + &quot;if (counter &gt; 0) then &quot; + &quot;redis.call(&apos;pexpire&apos;, KEYS[1], ARGV[2]); &quot; + &quot;return 0; &quot; + //否则证明锁已经释放，删除key并发布锁释放的消息 &quot;else &quot; + &quot;redis.call(&apos;del&apos;, KEYS[1]); &quot; + &quot;redis.call(&apos;publish&apos;, KEYS[2], ARGV[1]); &quot; + &quot;return 1; &quot;+ &quot;end; &quot; + &quot;return nil;&quot;, Arrays.&lt;Object&gt;asList(getName(), getChannelName()), LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(threadId));&#125; 如上代码，就是释放锁的逻辑。同样的，它也是有三个判断： 如果锁已经不存在，通过publish发布锁释放的消息，解锁成功 如果解锁的线程和当前锁的线程不是同一个，解锁失败，抛出异常 通过hincrby递减1，先释放一次锁。若剩余次数还大于0，则证明当前锁是重入锁，刷新过期时间；若剩余次数小于0，删除key并发布锁释放的消息，解锁成功 至此，Redisson中的可重入锁的逻辑，就分析完了。但值得注意的是，上面的两种实现方式都是针对单机Redis实例而进行的。如果我们有多个Redis实例，请参阅Redlock算法。该算法的具体内容，请参考redis.cn/topics/dist… 作者：清幽之地 链接：https://juejin.im/post/5c6e25aaf265da2dc538b4f9 来源：掘金 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[{"name":"分布式锁","slug":"分布式锁","permalink":"http://yoursite.com/categories/分布式锁/"}],"tags":[{"name":"分布式锁","slug":"分布式锁","permalink":"http://yoursite.com/tags/分布式锁/"}]},{"title":"Hello World","slug":"hello-world","date":"2019-01-02T07:49:20.670Z","updated":"2019-01-02T07:49:20.670Z","comments":true,"path":"2019/01/02/hello-world/","link":"","permalink":"http://yoursite.com/2019/01/02/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"Java内存模型深度剖析","slug":"Java内存模型深度剖析","date":"2019-01-02T07:49:20.670Z","updated":"2019-03-08T08:04:58.142Z","comments":true,"path":"2019/01/02/Java内存模型深度剖析/","link":"","permalink":"http://yoursite.com/2019/01/02/Java内存模型深度剖析/","excerpt":"","text":"为什么要有内存模型 在介绍Java内存模型之前，先来看一下到底什么是计算机内存模型，然后再来看Java内存模型在计算机内存模型的基础上做了哪些事情。要说计算机的内存模型，就要说一下一段古老的历史，看一下为什么要有内存模型。 内存模型，英文名Memory Model，他是一个很老的老古董了。他是与计算机硬件有关的一个概念。那么我先给你介绍下他和硬件到底有啥关系。 CPU和缓存一致性我们应该都知道，计算机在执行程序的时候，每条指令都是在CPU中执行的，而执行的时候，又免不了要和数据打交道。而计算机上面的数据，是存放在主存当中的，也就是计算机的物理内存啦。 刚开始，还相安无事的，但是随着CPU技术的发展，CPU的执行速度越来越快。而由于内存的技术并没有太大的变化，所以从内存中读取和写入数据的过程和CPU的执行速度比起来差距就会越来越大,这就导致CPU每次操作内存都要耗费很多等待时间。 这就像一家创业公司，刚开始，创始人和员工之间工作关系其乐融融，但是随着创始人的能力和野心越来越大，逐渐和员工之间出现了差距，普通员工原来越跟不上CEO的脚步。老板的每一个命令，传到到基层员工之后，由于基层员工的理解能力、执行能力的欠缺，就会耗费很多时间。这也就无形中拖慢了整家公司的工作效率。 可是，不能因为内存的读写速度慢，就不发展CPU技术了吧，总不能让内存成为计算机处理的瓶颈吧。 所以，人们想出来了一个好的办法，就是在CPU和内存之间增加高速缓存。缓存的概念大家都知道，就是保存一份数据拷贝。他的特点是速度快，内存小，并且昂贵。 那么，程序的执行过程就变成了： 当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。 之后，这家公司开始设立中层管理人员，管理人员直接归CEO领导，领导有什么指示，直接告诉管理人员，然后就可以去做自己的事情了。管理人员负责去协调底层员工的工作。因为管理人员是了解手下的人员以及自己负责的事情的。所以，大多数时候，公司的各种决策，通知等，CEO只要和管理人员之间沟通就够了。 而随着CPU能力的不断提升，一层缓存就慢慢的无法满足要求了，就逐渐的衍生出多级缓存。 按照数据读取顺序和与CPU结合的紧密程度，CPU缓存可以分为一级缓存（L1），二级缓存（L3），部分高端CPU还具有三级缓存（L3），每一级缓存中所储存的全部数据都是下一级缓存的一部分。 这三种缓存的技术难度和制造成本是相对递减的，所以其容量也是相对递增的。 那么，在有了多级缓存之后，程序的执行就变成了： 当CPU要读取一个数据时，首先从一级缓存中查找，如果没有找到再从二级缓存中查找，如果还是没有就从三级缓存或内存中查找。 随着公司越来越大，老板要管的事情越来越多，公司的管理部门开始改革，开始出现高层，中层，底层等管理者。一级一级之间逐层管理。 单核CPU只含有一套L1，L2，L3缓存； 如果CPU含有多个核心，即多核CPU，则每个核心都含有一套L1（甚至和L2）缓存，而共享L3（或者和L2）缓存。 公司也分很多种，有些公司只有一个大Boss，他一个人说了算。但是有些公司有比如联席总经理、合伙人等机制。 单核CPU就像一家公司只有一个老板，所有命令都来自于他，那么就只需要一套管理班底就够了。 多核CPU就像一家公司是由多个合伙人共同创办的，那么，就需要给每个合伙人都设立一套供自己直接领导的高层管理人员，多个合伙人共享使用的是公司的底层员工。 还有的公司，不断壮大，开始差分出各个子公司。各个子公司就是多个CPU了，互相之前没有共用的资源。互不影响。 下图为一个单CPU双核的缓存结构。 CACHE随着计算机能力不断提升，开始支持多线程。那么问题就来了。我们分别来分析下单线程、多线程在单核CPU、多核CPU中的影响。 单线程。cpu核心的缓存只被一个线程访问。缓存独占，不会出现访问冲突等问题。 单核CPU，多线程。进程中的多个线程会同时访问进程中的共享数据，CPU将某块内存加载到缓存后，不同线程在访问相同的物理地址的时候，都会映射到相同的缓存位置，这样即使发生线程的切换，缓存仍然不会失效。但由于任何时刻只能有一个线程在执行，因此不会出现缓存访问冲突。 多核CPU，多线程。每个核都至少有一个L1 缓存。多个线程访问进程中的某个共享内存，且这多个线程分别在不同的核心上执行，则每个核心都会在各自的caehe中保留一份共享内存的缓冲。由于多核是可以并行的，可能会出现多个线程同时写各自的缓存的情况，而各自的cache之间的数据就有可能不同。 在CPU和主存之间增加缓存，在多线程场景下就可能存在缓存一致性问题，也就是说，在多核CPU中，每个核的自己的缓存中，关于同一个数据的缓存内容可能不一致。 如果这家公司的命令都是串行下发的话，那么就没有任何问题。 如果这家公司的命令都是并行下发的话，并且这些命令都是由同一个CEO下发的，这种机制是也没有什么问题。因为他的命令执行者只有一套管理体系。 如果这家公司的命令都是并行下发的话，并且这些命令是由多个合伙人下发的，这就有问题了。因为每个合伙人只会把命令下达给自己直属的管理人员，而多个管理人员管理的底层员工可能是公用的。 比如，合伙人1要辞退员工a，合伙人2要给员工a升职，升职后的话他再被辞退需要多个合伙人开会决议。两个合伙人分别把命令下发给了自己的管理人员。合伙人1命令下达后，管理人员a在辞退了员工后，他就知道这个员工被开除了。而合伙人2的管理人员2这时候在没得到消息之前，还认为员工a是在职的，他就欣然的接收了合伙人给他的升职a的命令。 一致处理器优化和指令重排上面提到在在CPU和主存之间增加缓存，在多线程场景下会存在缓存一致性问题。除了这种情况，还有一种硬件问题也比较重要。那就是为了使处理器内部的运算单元能够尽量的被充分利用，处理器可能会对输入代码进行乱序执行处理。这就是处理器优化。 除了现在很多流行的处理器会对代码进行优化乱序处理，很多编程语言的编译器也会有类似的优化，比如Java虚拟机的即时编译器（JIT）也会做指令重排。 可想而知，如果任由处理器优化和编译器对指令重排的话，就可能导致各种各样的问题。 关于员工组织调整的情况，如果允许人事部在接到多个命令后进行随意拆分乱序执行或者重排的话，那么对于这个员工以及这家公司的影响是非常大的。 并发编程的问题 前面说的和硬件有关的概念你可能听得有点蒙，还不知道他到底和软件有啥关系。但是关于并发编程的问题你应该有所了解，比如原子性问题，可见性问题和有序性问题。 其实，原子性问题，可见性问题和有序性问题。是人们抽象定义出来的。而这个抽象的底层问题就是前面提到的缓存一致性问题、处理器优化问题和指令重排问题等。 这里简单回顾下这三个问题，并不准备深入展开，感兴趣的读者可以自行学习。我们说，并发编程，为了保证数据的安全，需要满足以下三个特性： 原子性是指在一个操作中就是cpu不可以在中途暂停然后再调度，既不被中断操作，要不执行完成，要不就不执行。 可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 有序性即程序执行的顺序按照代码的先后顺序执行。 有没有发现，缓存一致性问题其实就是可见性问题。而处理器优化是可以导致原子性问题的。指令重排即会导致有序性问题。所以，后文将不再提起硬件层面的那些概念，而是直接使用大家熟悉的原子性、可见性和有序性。 什么是内存模型 前面提到的，缓存一致性问题、处理器器优化的指令重排问题是硬件的不断升级导致的。那么，有没有什么机制可以很好的解决上面的这些问题呢？ 最简单直接的做法就是废除处理器和处理器的优化技术、废除CPU缓存，让CPU直接和主存交互。但是，这么做虽然可以保证多线程下的并发问题。但是，这就有点因噎废食了。 所以，为了保证并发编程中可以满足原子性、可见性及有序性。有一个重要的概念，那就是——内存模型。 为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范。通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性。它与处理器有关、与缓存有关、与并发有关、与编译器也有关。他解决了CPU多级缓存、处理器优化、指令重排等导致的内存访问问题，保证了并发场景下的一致性、原子性和有序性。 内存模型解决并发问题主要采用两种方式：限制处理器优化和使用内存屏障。本文就不深入底层原理来展开介绍了，感兴趣的朋友可以自行学习。 什么是Java内存模型 前面介绍过了计算机内存模型，这是解决多线程场景下并发问题的一个重要规范。那么具体的实现是如何的呢，不同的编程语言，在实现上可能有所不同。 我们知道，Java程序是需要运行在Java虚拟机上面的，Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。 提到Java内存模型，一般指的是JDK 5 开始使用的新的内存模型，主要由JSR-133: JavaTM Memory Model and Thread Specification 描述。感兴趣的可以参看下这份PDF文档（http://www.cs.umd.edu/~pugh/java/memoryModel/jsr133.pdf） Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。 而JMM就作用于工作内存和主存之间数据同步过程。他规定了如何做数据同步以及什么时候做数据同步。 JAVA这里面提到的主内存和工作内存，读者可以简单的类比成计算机内存模型中的主存和缓存的概念。特别需要注意的是，主内存和工作内存与JVM内存结构中的Java堆、栈、方法区等并不是同一个层次的内存划分，无法直接类比。《深入理解Java虚拟机》中认为，如果一定要勉强对应起来的话，从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分。工作内存则对应于虚拟机栈中的部分区域。 所以，再来总结下，JMM是一种规范，目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。目的是保证并发编程场景中的原子性、可见性和有序性。 Java内存模型的实现 了解Java多线程的朋友都知道，在Java中提供了一系列和并发处理相关的关键字，比如volatile、synchronized、final、concurren包等。其实这些就是Java内存模型封装了底层的实现后提供给程序员使用的一些关键字。 在开发多线程的代码的时候，我们可以直接使用synchronized等关键字来控制并发，从来就不需要关心底层的编译器优化、缓存一致性等问题。所以，Java内存模型，除了定义了一套规范，还提供了一系列原语，封装了底层实现后，供开发者直接使用。 本文并不准备把所有的关键字逐一介绍其用法，因为关于各个关键字的用法，网上有很多资料。读者可以自行学习。本文还有一个重点要介绍的就是，我们前面提到，并发编程要解决原子性、有序性和一致性的问题，我们就再来看下，在Java中，分别使用什么方式来保证。 原子性在Java中，为了保证原子性，提供了两个高级的字节码指令monitorenter和monitorexit。在synchronized的实现原理文章中，介绍过，这两个字节码，在Java中对应的关键字就是synchronized。 因此，在Java中可以使用synchronized来保证方法和代码块内的操作是原子性的。 可见性Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值的这种依赖主内存作为传递媒介的方式来实现的。 Java中的volatile关键字提供了一个功能，那就是被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次是用之前都从主内存刷新。因此，可以使用volatile来保证多线程操作时变量的可见性。 除了volatile，Java中的synchronized和final两个关键字也可以实现可见性。只不过实现方式不同，这里不再展开了。 有序性在Java中，可以使用synchronized和volatile来保证多线程之间操作的有序性。实现方式有所区别： volatile关键字会禁止指令重排。synchronized关键字保证同一时刻只允许一条线程操作。 好了，这里简单的介绍完了Java并发编程中解决原子性、可见性以及有序性可以使用的关键字。读者可能发现了，好像synchronized关键字是万能的，他可以同时满足以上三种特性，这其实也是很多人滥用synchronized的原因。 但是synchronized是比较影响性能的，虽然编译器提供了很多锁优化技术，但是也不建议过度使用。 总结 在读完本文之后，相信你应该了解了什么是Java内存模型、Java内存模型的作用以及Java中内存模型做了什么事情等。","categories":[{"name":"内存模型","slug":"内存模型","permalink":"http://yoursite.com/categories/内存模型/"}],"tags":[{"name":"内存模型","slug":"内存模型","permalink":"http://yoursite.com/tags/内存模型/"}]},{"title":"通过面试题，让我们来了解Collection","slug":"通过面试题，让我们来了解Collection","date":"2019-01-02T07:49:20.670Z","updated":"2019-03-26T08:24:40.521Z","comments":true,"path":"2019/01/02/通过面试题，让我们来了解Collection/","link":"","permalink":"http://yoursite.com/2019/01/02/通过面试题，让我们来了解Collection/","excerpt":"","text":"前言本章主要介绍Collection集合相关知识，结合面试中会提到的相关问题进行知识点的梳理。希望能帮到大家~ 基于JDK1.8，如有错误，还望大家能够指出！ 涉及的Collection集合相关面试题 1.什么是集合？ 2.AVA中集合类型都有哪些？有什么特点？ 3.说一说集合的父类Collection？ 4.数组和集合都有哪些区别？ 5.说一说迭代器Iterator 6.Collection接口中几种重要的类和接口简介 1.什么是集合？来自百度百科的回答： 12345集合类存放于java.util包中。集合类存放的都是对象的引用，而非对象本身，出于表达上的便利，我们称集合中的对象就是指集合中对象的引用（reference)。集合类型主要有3种：set(集）、list(列表）和map(映射)。集合接口分为：Collection和Map，list、set实现了Collection接口 2.JAVA中集合类型都有哪些？各有什么特点？Collection两大体系：链表List、集合SetList特点：元素有序；元素可以重复；元素都有索引（角标） List里存放的对象是有序的，同时也是可以重复的，List关注的是索引，拥有一系列和索引相关的方法，查询速度快。因为往list集合里插入或删除数据时，会伴随着后面数据的移动，所有插入删除数据速度慢。 Set特点：元素无序；元素不可以重复； Set里存放的对象是无序，不能重复的，集合中的对象不按特定的方式排序，只是简单地把对象加入集合中。 同时集合中还有另外一种类型：Map(映射)。 Map特点：键值对；键不可以重复；值可以重复； Map集合中存储的是键值对，键不能重复，值可以重复。根据键得到值，对map集合遍历时先得到键的set集合，对set集合进行遍历，得到相应的值。 3.说一说集合的父类Collection？3.1 Collection 体系结构图 CollectionList:有序集合，允许相同元素和null） –LinkedList （非同步，允许相同元素和null，遍历效率低插入和删除效率高） –ArrayList （非同步，允许相同元素和null，实现了动态大小的数组，遍历效率高，用的多） –Vector（同步，允许相同元素和null，效率低） —Stack（继承自Vector，实现一个后进先出的堆栈Set （无序集合，不允许相同元素，最多有一个null元素） –HashSet(无序集合，不允许相同元素，最多有一个null元素) Map （没有实现collection接口，key不能重复，value可以重复，一个key映射一个value） –Hashtable （实现Map接口，同步，不允许null作为key和value，用自定义的类当作key的话要复写hashCode和eques方法，） –HashMap （实现Map接口，非同步，允许null作为key和value，用的多） –WeakHashMap（实现Map接口） 3.2 Collection 中的主要方法（1）添加boolean add(E o);boolean add(Collection&lt;? extends E&gt; c); （2）删除boolean remove(Object o);boolean removeAll(Collection&lt;? extends E&gt; c)void clear()； （3）判断 a.判断集合中是否有元素：boolean isEmpty();b.判断集合中是否包含某个元素：boolean contains(Object o);c.判断集合中是否包含某些元素：boolean contains(Collection&lt;?&gt; c); （4）获取a.获取集合中元素个数：int size();b.遍历集合中所有元素：Iterator iterator();c.判断两个集合中是否存在相同的元素并保留两个集合中相同的元素删除不同的元素：boolean retainAll(Collection&lt;?&gt; c); （5）其他将集合中元素转为数组: a. Ojbect[] toArray();b. T[] toArray(); 泛型Java8新增方法：在 JDK 8 以后，Collection 接口还提供了从集合获取连续的或者并行流：Stream stream()Stream parallelStream()于Collection接口相关还有一个抽象类AbstractCollection：AbstractCollection是一个抽象类，实现了Collection接口的部分功能，实现了一些最基本的通用操作，把复杂的和业务相关的延迟到子类实现。在AbstractCollection中，主要实现了contains(), isEmpty(), toArray(), remove(), clear() 这几个操作。有兴趣的同学可以自行研究下，逻辑都比较简单。特别注意：List接口扩展了一个一些方法，其中最重要，也是用的最多的是：E get(int index) 返回指定索引的元素 4.数组和集合都有哪些区别？数组特点： 1.数组本质上就是一段连续的内存空间，用于记录多个类型相同的数据；2.数据一旦声明完毕，则内存空间固定不变；3.插入和删除操作不方便，可能会移动大量的元素并导致效率太低；4.支持下标访问，可以实现随机访问；5.数组中的元素可以是基本数据类型，也可以使用引用数据类型。 集合特点： 1.内存空间可以不连续，数据类型可以不相同；2.集合的内存空间可以动态的调整；3.集合的插入删除操作可以不移动大量元素；4.部分支持下标访问，部分不支持；5.集合中的元素必须是引用数据类型(你存储的是简单的int，它会自动装箱成Integer)； 可以看出数组和集合在数据的存储，访问，类型，长度等都有不同的地方。 5.说一说迭代器 Iterator？ （1）通过集合对象获取其对应的Iterator对象 （2）判断是否存在下一个元素 （3）取出该元素并将迭代器对象指向下一个元素 Iterator iterator():取出元素的方式：迭代器。 1234该对象必须依赖于具体容器，因为每一个容器的数据结构都不同。所以该迭代器对象是在容器中进行内部实现的。对于使用容器者而言，具体的实现不重要，只要通过容器获取到该实现的迭代器的对象即可，也就是iterator方法。 扩展知识：ArrayList里面的iterator方法采用了设计模式中的——工厂方法模式！有兴趣的同学可以后续看到我另外的文章“设计模式精讲”专栏。 6.Collection接口中几种重要的类和接口简介？该问题与第二个问题类似~ 后续文章会有更详细的介绍！Collection两大体系：链表List、集合Set 另映射Map List接口及子类介绍 List是有序的Collection，使用此接口能够精确的控制每个元素插入的位置。用户能够使用索引（元素在List中的位置，类似于数组下标）来访问List中的元素，这类似于Java的数组。 和下面要提到的Set不同，List允许有相同的元素。 除了具有Collection接口必备的iterator()方法外，List还提供一个listIterator()方法，返回一个ListIterator接口，和标准的Iterator接口相比，ListIterator多了一些add()之类的方法，允许添加，删除，设定元素，还能向前或向后遍历。 实现List接口的常用类有： LinkedList类 （底层数据结构是链表，线程不安全） ArrayList类 （底层数据结构是数组，线程不安全） Vector类 （底层数据结构是数组，线程安全） Stack类 （顾名思义：栈，继承至Vector类并进行扩展）在后续的文章中我们将一一详细介绍这些类的相关特性！ Set接口及子类介绍Set是一种不包含重复的元素的Collection，即任意的两个元素e1和e2都有e1.equals(e2)=false，Set最多有一个null元素。很明显，Set的构造函数有一个约束条件，传入的Collection参数不能包含重复的元素。 注意：必须小心操作可变对象（Mutable Object）。如果一个Set中的可变元素改变了自身状态导致Object.equals(Object)=true将导致一些问题。实现Set接口的常用类有： HashSet类 （底层数据结构是数组+单链表+红黑树，无序） LinkedHashSet （底层数据结构是数组+单链表+红黑树+双向链表，无序） TreeSet类 （底层数据结构红黑树，有序）在后续的文章中我们将一一详细介绍这些类的相关特性！ Map接口及子类介绍 注意：Map没有继承Collection接口，Map提供key到value的映射。一个Map中不能包含相同的key，每个key只能映射一个value。Map接口提供3种集合的视图，Map的内容可以被当作一组key集合，一组value集合，或者一组key-value映射。 Hashtable类 HashMap类 在后续的文章中我们将一一详细介绍这些类的相关特性！ 文末本章节介绍了Collection接口中的大部分可能在面试过程中会出现的内容，并没有详细去介绍其子类及其实现相关的原理。这方面的内容会放在后续的章节中去详细介绍。 作者：Coder编程 链接：https://juejin.im/post/5c91df2fe51d454b5c53a335 来源：掘金 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[{"name":"Collection","slug":"Collection","permalink":"http://yoursite.com/categories/Collection/"}],"tags":[{"name":"Collection","slug":"Collection","permalink":"http://yoursite.com/tags/Collection/"}]},{"title":"jdk1.8 线程池部分源码分析","slug":"jdk1.8 线程池部分源码分析","date":"2019-01-02T07:49:20.670Z","updated":"2019-03-08T08:04:25.715Z","comments":true,"path":"2019/01/02/jdk1.8 线程池部分源码分析/","link":"","permalink":"http://yoursite.com/2019/01/02/jdk1.8 线程池部分源码分析/","excerpt":"","text":"普通线程 1.实现：继承Thread或者实现Runnable接口 1.继承Thread，仅仅只能单继承2.实现Runnable接口（可实现内部资源共享），接口可以多实现3.经典问题：窗口卖票 2.实例化对象3.执行任务4.销毁线程回收资源 思考：当多个资源需要开启线程来处理的时候，我们怎么办？是否一直在重复下面的流程： create -&gt; run -&gt; destroy复制代码我们知道计算机的每次运行都是需要大量的资源消耗，5个线程的操作可能没有影响，5w个呢？ 五万次创建和销毁才有仅仅五万次的执行吗？执行任务可能花费了大量的时间来处理这些创建和销毁。 线程池 特点 1.解决处理器单元内多个线程的执行问题2.减少处理器单元闲置时间3.增加了处理器单元工作时间内的吞吐能力（为什么这么说？我们减少了多个任务每次线程的创建和销毁浪费，提高了任务执行效率） 组成 1.线程池管理器（ThreadPool）：负责创建、管理、销毁线程池，以及添加任务2.工作线程（PoolWorker）：无任务则等待，可循环、重复执行任务3.任务接口（Task）：每个任务必须实现接口，工作线程负责调度任务的执行，规定了任务的入口，以及任务完成后的收尾工作以及任务执行状态等等4.任务队列（TaskQueue）：存放没有处理的任务，提供任务缓冲机制 eg：超市结账：收营员服务组，单个收营员，收银工作，等待被收银的人群JDK线程池类：java.util.concurrent.Executors和JDK线程池执行器接口：java.util.concurrent.Executor在Executors中，jdk提供了一下相关的线程池，如下： 静态方法创建的线程池类型返回值的实际实现 newFixedThreadPool(int)固定线程池ThreadPoolExecutor newWorkStealingPool()处理器核心数的并行线程池ForkJoinPool newSingleThreadExecutor()一个线程的单独线程池FinalizableDelegatedExecutorService newCachedThreadPool()缓存线程池ThreadPoolExecutor newSingleThreadScheduledExecutor()单独线程定时线程池DelegatedScheduledExecutorService newScheduledThreadPool(int)定时线程池ScheduledThreadPoolExecutor newSingleThreadExecutor() 一个线程的线程池 为什么这里我要拿一个线程的线程池来说明呢？其实我们把简单的搞定复杂的也是演变过来的。先上码：public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue()));} public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue(), threadFactory));}复制代码我们可以看到上面方法的返回值都是ExecutorService，但实际上实例化的是FinalizableDelegatedExecutorService，我们进去看看源码，如下：static class FinalizableDelegatedExecutorService extends DelegatedExecutorService { //构造方法 FinalizableDelegatedExecutorService(ExecutorService executor) { super(executor); } //对象销毁的时候调用 protected void finalize() { super.shutdown(); } }复制代码上面的代码我们可以明显的看到FinalizableDelegatedExecutorService仅仅是对DelegatedExecutorService的封装，唯一实现的就是在对象销毁的时候将ExecutorService结束。到这里我们就应该返回来分析DelegatedExecutorService，以及上面的方法中的具体代码。我们看看默认的单线程线程池的实现，如下：new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue()));//此处的代码实现了一个ExecutorService，分别有几个参数？何解？ //public class ThreadPoolExecutor extends AbstractExecutorService { public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); }}//我们可以看到几个参数的字面意思分别是：//corePoolSize 核心线程数量，包括空闲线程//maximumPoolSize 最大线程数量//keepAliveTime 保持活跃时间（参照后续源码，这里应该是：当线程数大于核心时，此为终止前多余的空闲线程等待新任务的最长时间）//unit keepAliveTime 参数的时间单位//workQueue 执行前用于保持任务的队列。此队列仅保持由 execute方法提交的 Runnable任务//Executors.defaultThreadFactory() 默认线程工厂//defaultHandler 超出线程和任务队列的任务的处理程序，实现为：new AbortPolicy()，当然这里默认是没有处理的，需要我们手动实现 //这里，我们接着看默认的线程工厂，毕竟线程池核心是需要线程来执行任务，所以此处先看线程来源。static class DefaultThreadFactory implements ThreadFactory { //池数量，指定原子操作 private static final AtomicInteger poolNumber = new AtomicInteger(1); //线程组 private final ThreadGroup group; //线程数量，指定原子操作 private final AtomicInteger threadNumber = new AtomicInteger(1); //线程名称前缀 private final String namePrefix; DefaultThreadFactory() { //获取系统安全管理器 SecurityManager s = System.getSecurityManager(); //创建线程组，由是否获取系统安全管理器决定 group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); //构造线程名称 namePrefix = &quot;pool-&quot; + poolNumber.getAndIncrement() + &quot;-thread-&quot;; } //创建线程 public Thread newThread(Runnable r) { //将线程组、Runnable接口（线程实际执行代码块）、线程名、线程所需要的堆栈大小为0 Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); //如果为守护线程，取消守护状态，必须在线程执行前调用这个setDaemon方法 if (t.isDaemon()) t.setDaemon(false); //默认任务优先级，值为5 if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; } }//上面的默认线程工厂，提供给了我们一个非守护线程的线程，由原子操作保证线程唯一，任务优先级默认（最低1，最高10，默认5，此处优先级为5） 复制代码看了上面这些我们可以总结一下：单线程线程池，默认只有一个线程和一个线程池，等待新任务时间为0，添加了原子操作来绑定线程。是不是到这里就完了？ 当然没有，我们现在需要看看更加具体的ThreadPoolExecutor，才能更加深入明白线程池。public class ThreadPoolExecutor extends AbstractExecutorService { /* 所有的构造方法均指向这里，所以我们看一下这个就足够 */ public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { //参数检查，说明线程池不能线程=0，也不能最大线程数量不大于0切最大线程数量不能少于核心线程数量，等待任务最长时间不能小于0 if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); //等待任务队列、线程工厂、超任务队列的处理程序 if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); //上面的判断，可以看做是一种防御式编程，所有的问题预先处理，后续无需考虑类似问题 //构造线程池相关设定阈值 this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; }} //到了这里其实我们不必先追究具体的实现，还是先看看AbstractExecutorService吧。 //抽象的执行服务public abstract class AbstractExecutorService implements ExecutorService { //执行方法 private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException { if (tasks == null) throw new NullPointerException(); //获取任务数量 int ntasks = tasks.size(); if (ntasks == 0) throw new IllegalArgumentException(); //任务集合 ArrayList&lt;Future&lt;T&gt;&gt; futures = new ArrayList&lt;Future&lt;T&gt;&gt;(ntasks); //执行完成服务 ExecutorCompletionService&lt;T&gt; ecs = new ExecutorCompletionService&lt;T&gt;(this); try { // 记录异常 ExecutionException ee = null; //超时时间线 final long deadline = timed ? System.nanoTime() + nanos : 0L; //使用迭代器获取任务 Iterator&lt;? extends Callable&lt;T&gt;&gt; it = tasks.iterator(); // 确定开始一项任务 futures.add(ecs.submit(it.next())); //任务数量减少 --ntasks; //正在执行任务标志 int active = 1; //循环执行任务 for (;;) { //获取任务队列中第一个任务 Future&lt;T&gt; f = ecs.poll(); //任务为空，如果还有任务则执行任务（任务数量减1，提交任务到执行队列，正在执行任务数量+1） //正在执行任务数为0，说明任务执行完毕，中断任务循环 //若有超时检查，则执行超时检查机制 //上述情况都不满足，则取出任务队列头，并将其从队列移除 if (f == null) { if (ntasks &gt; 0) { --ntasks; futures.add(ecs.submit(it.next())); ++active; } else if (active == 0) break; else if (timed) { f = ecs.poll(nanos, TimeUnit.NANOSECONDS); if (f == null) throw new TimeoutException(); nanos = deadline - System.nanoTime(); } else f = ecs.take(); } //任务不为空 if (f != null) { //正在执行标志-1 --active; try { //返回执行结果 return f.get(); } catch (ExecutionException eex) { ee = eex; } catch (RuntimeException rex) { ee = new ExecutionException(rex); } } } if (ee == null) ee = new ExecutionException(); throw ee; } finally { //取消所有任务 for (int i = 0, size = futures.size(); i &lt; size; i++) futures.get(i).cancel(true); } } //执行方法 public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException { if (tasks == null) throw new NullPointerException(); long nanos = unit.toNanos(timeout); //和上面类似，这里也是创建任务队列 ArrayList&lt;Future&lt;T&gt;&gt; futures = new ArrayList&lt;Future&lt;T&gt;&gt;(tasks.size()); boolean done = false; //迭代进行任务执行 try { //创建任务，并添加到任务队列 for (Callable&lt;T&gt; t : tasks) futures.add(newTaskFor(t)); //设置超时时间标记 final long deadline = System.nanoTime() + nanos; final int size = futures.size(); //在执行器没有多少多并行性的情况下，交替执行时间检查和调用。 for (int i = 0; i &lt; size; i++) { execute((Runnable)futures.get(i)); nanos = deadline - System.nanoTime(); //任务超时，返回任务队列 if (nanos &lt;= 0L) return futures; } //遍历任务并返回任务执行结果 for (int i = 0; i &lt; size; i++) { Future&lt;T&gt; f = futures.get(i); if (!f.isDone()) { //超时 if (nanos &lt;= 0L) return futures; try { //给定执行时间等待任务完成并返回结果 f.get(nanos, TimeUnit.NANOSECONDS); } catch (CancellationException ignore) { } catch (ExecutionException ignore) { } catch (TimeoutException toe) { return futures; } nanos = deadline - System.nanoTime(); } } done = true; return futures; } finally { //未完成则取消执行 if (!done) for (int i = 0, size = futures.size(); i &lt; size; i++) futures.get(i).cancel(true); } } /** *创建任务队列 */ protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) { return new FutureTask&lt;T&gt;(runnable, value); } /** * 提交任务到执行队列 */ public Future&lt;?&gt; submit(Runnable task) { if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask; } }复制代码通过上面的代码我们已经基本了解了一个线程池是如何创建任务队列并执行任务的，所以在这里我们只需要关注一些关键的ThreadPoolExecutor的方法就能了解线程池是如何工作的，并且对应的几种模式的线程池都可以推导出来。首先在这次看源码之前我们要胡乱思索一番，整理一下线程池的执行大概流程： 我们前面简单的说过几个ThreadPoolExecutor的主要参数，我们下面再仔细总结一下：public class ThreadPoolExecutor extends AbstractExecutorService { public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; } }复制代码corePoolSize：该线程池中核心线程数最大值 核心线程：线程池新建线程的时候，如果当前线程总数小于corePoolSize，则新建的是核心线程，如果超过corePoolSize，则新建的线程不是核心线程。核心线程默认情况下会一直存活在线程池中，即使这个核心线程啥也不干(闲置状态)。如果指定ThreadPoolExecutor的allowCoreThreadTimeOut这个属性为true，那么核心线程如果不干活(闲置状态)的话，超过一定时间(时长下面参数决定)，就会被销毁掉。 maximumPoolSize： 该线程池中线程总数最大值 线程总数 = 核心线程数 + 非核心线程数。 keepAliveTime：该线程池中非核心线程闲置超时时长 一个非核心线程，如果不干活(闲置状态)的时长超过这个参数所设定的时长，就会被销毁掉，如果设置allowCoreThreadTimeOut = true，则会作用于核心线程。 unit：keepAliveTime的单位 TimeUnit是一个枚举类型，其包括：NANOSECONDS ： 1微毫秒 = 1微秒 / 1000MICROSECONDS ： 1微秒 = 1毫秒 / 1000MILLISECONDS ： 1毫秒 = 1秒 /1000SECONDS ： 秒MINUTES ： 分HOURS ： 小时DAYS ： 天 workQueue：线程池中的任务队列：维护着等待执行的Runnable对象 当所有的核心线程都在干活时，新添加的任务会被添加到这个队列中等待处理，如果队列满了，则新建非核心线程执行任务。 threadFactory：创建线程的方式。 handler：异常处理程序。 既然已经知道了任务执行，那么任务是怎么排队的呢？public void execute(Runnable command) { if (command == null) throw new NullPointerException(); /* * 1. 如果运行的线程少于corepoolSize大小，新任务会直接开启新的线程执行。 * 对addWorker的调用原子性地检查运行状态和workerCount，从而通过返回false防止假警报，假警报会在不应该的情况下添加线程。 * * 2. 如果一个任务成功的加入队列，我们需要再次检查是否需要开启新的线程来执行。 * 可能原因有：已有任务执行完毕，或者线程池已经被结束。 * * * 3. 如果不能对任务进行排队，则尝试添加一个新任务线程。 * 如果它失败了，我们知道我们已经关闭或饱和了所以拒绝这个任务。 */ //运行状态标签 int c = ctl.get(); //正在执行的线程数 &lt; 核心线程数 ，则立即执行任务 if (workerCountOf(c) &lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } //再次检查是否运行且没超过任务队列容量 if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); //需要执行的任务不在运行状态且不在等待队列，则将这个任务异常抛出 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); //运行任务数量为空，则将核心线程外的线程任务置空 else if (workerCountOf(recheck) == 0) addWorker(null, false); } //超过核心线程数且其他线程任务也添加失败，抛出异常 else if (!addWorker(command, false)) reject(command); } 复制代码看到这里我们已经模模糊糊的明白了任务排队执行，所有的任务队列都是一样的排队执行，那么我们任务队列又有哪些呢？ LinkedBlockingQueue：线性阻塞队列。接收到任务，如果没超过corePoolSize，则创建新线程执行，否则进入阻塞队列等待 ArrayBlockingQueue：数组阻塞队列。数组特诊是长度固定，也就是这个队列长度固定。接收到新任务，如果没超过corePoolSize，则创建新线程执行，如果超过，则创建新线程（线程总数&lt;maximumPoolSize）执行。如果新任务既不能在队列中等待，又不能执行，抛出异常。 SynchronousQueue：同步队列。 既然是同步队列，说明新任务来了就执行。也就是核心线程数量无限大。 DelayQueue：延迟队列，听名字也知道任务要延迟执行，这个队列接收到任务时，首先先入队，只有达到了指定的延时时间，才会执行任务。 也就是说到了这里，我们基本已经分析了线程池的几个核心：jdk自带线程池种类、线程池内的线程工厂（用于生产线程）、线程池任务执行、线程池任务排队、线程池队列类型。我们总结一张图，可以结束本篇文章，当然其他类型的线程池具体实现，请自行查看源码。 思考：在Java开发中还有哪些类似的东西是这种操作的呢？ 作者：pc859107393链接：https://juejin.im/post/5ba28fb36fb9a05d2c43a57a来源：掘金著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[{"name":"线程池","slug":"线程池","permalink":"http://yoursite.com/categories/线程池/"}],"tags":[{"name":"线程池","slug":"线程池","permalink":"http://yoursite.com/tags/线程池/"}]}]}