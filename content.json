{"meta":{"title":"Hexo","subtitle":null,"description":null,"author":"John Doe","url":"http://yoursite.com"},"pages":[{"title":"关于","date":"2019-01-18T07:23:07.452Z","updated":"2019-01-18T07:23:07.452Z","comments":false,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"123456789101112131415161718192021222324252627282930&#123; name: 'znn' age: 24, gender: '男', profession: 'Web Developer &amp; Designer', experience: '4年', github: 'https://github.com/znnspace', blog: 'http://blog.znnspace.com', email: 'znnspace@foxmail.com', description: '致力于网站建设与前端用户体验设计', skills: [ ['Html', 'Javascript', 'jQuery', 'CSS', 'ES6', 'Node'], ['Webpack', 'Gulp'], ['Less','Sass'], ['Git', 'SVN'], ['Vue'], ['Bootstrap', 'SUI Mobile', 'light7'], ['WordPress', 'OpenCart'], ['平面设计'] ], devTools: [ ['Sublime Text', 'Visual Studio Code', 'Notepad++'], ['Chrome DevTools', 'Fiddler'], ['SourceTree', 'TortoiseSVN'], ['SwitchHosts'], ['Navicat', 'XAMPP'], ] &#125;"},{"title":"书单","date":"2019-01-11T02:58:06.971Z","updated":"2019-01-02T07:50:11.790Z","comments":false,"path":"books/index.html","permalink":"http://yoursite.com/books/index.html","excerpt":"","text":""},{"title":"分类","date":"2019-01-11T03:01:41.796Z","updated":"2019-01-02T07:50:11.790Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"友情链接","date":"2019-01-18T07:01:24.126Z","updated":"2019-01-02T07:50:11.790Z","comments":true,"path":"links/index.html","permalink":"http://yoursite.com/links/index.html","excerpt":"","text":""},{"title":"Repositories","date":"2019-01-18T07:25:43.238Z","updated":"2019-01-02T07:50:11.790Z","comments":false,"path":"repository/index.html","permalink":"http://yoursite.com/repository/index.html","excerpt":"","text":""},{"title":"标签","date":"2019-01-18T07:23:39.338Z","updated":"2019-01-02T07:50:11.790Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"Docker(一)：Docker入门教程","slug":"Docker(一)：Docker入门教程","date":"2019-03-27T16:00:00.000Z","updated":"2019-03-28T11:17:34.877Z","comments":true,"path":"2019/03/28/Docker(一)：Docker入门教程/","link":"","permalink":"http://yoursite.com/2019/03/28/Docker(一)：Docker入门教程/","excerpt":"","text":"如今Docker的使用已经非常普遍，特别在一线互联网公司。使用Docker技术可以帮助企业快速水平扩展服务，从而到达弹性部署业务的能力。在云服务概念兴起之后，Docker的使用场景和范围进一步发展，如今在微服务架构越来越流行的情况下，微服务+Docker的完美组合，更加方便微服务架构运维部署落地。 本文详细解释介绍Docker入门相关内容，后期重点关注Docker在微服务体系中的使用。在了解Docker之前我们先考虑几个问题：1、Docker是什么？2、为什么要使用Docker，它有什么优势？带着这些问题我们来看看下面的内容。 什么是Docker?Docker 是世界领先的软件容器平台。开发人员利用 Docker 可以消除协作编码时“在我的机器上可正常工作”的问题。运维人员利用 Docker 可以在隔离容器中并行运行和管理应用，获得更好的计算密度。企业利用 Docker 可以构建敏捷的软件交付管道，以更快的速度、更高的安全性和可靠的信誉为 Linux 和 Windows Server 应用发布新功能。 Docker 属于 Linux 容器的一种封装，提供简单易用的容器使用接口。它是目前最流行的 Linux 容器解决方案。Docker 将应用程序与该程序的依赖，打包在一个文件里面。运行这个文件，就会生成一个虚拟容器。程序在这个虚拟容器里运行，就好像在真实的物理机上运行一样。有了 Docker，就不用担心环境问题。 总体来说，Docker 的接口相当简单，用户可以方便地创建和使用容器，把自己的应用放入容器。容器还可以进行版本管理、复制、分享、修改，就像管理普通的代码一样。 Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，它是基于 dotCloud 公司多年云服务技术的一次革新，并于 2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护。Docker 项目后来还加入了 Linux 基金会，并成立推动 开放容器联盟（OCI）。 Docker 自开源后受到广泛的关注和讨论，至今其 GitHub 项目已经超过 4 万 6 千个星标和一万多个 fork。甚至由于 Docker 项目的火爆，在 2013 年底，dotCloud 公司决定改名为 Docker。Docker 最初是在 Ubuntu 12.04 上开发实现的；Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持；Google 也在其 PaaS 产品中广泛应用 Docker。 为什么要使用Docker容器除了运行其中应用外，基本不消耗额外的系统资源，使得应用的性能很高，同时系统的开销尽量小。传统虚拟机方式运行 10 个不同的应用就要起 10 个虚拟机，而Docker 只需要启动 10 个隔离的应用即可。 具体说来，Docker 在如下几个方面具有较大的优势。 1、更快速的交付和部署 对开发和运维（devop）人员来说，最希望的就是一次创建或配置，可以在任意地方正常运行。 开发者可以使用一个标准的镜像来构建一套开发容器，开发完成之后，运维人员可以直接使用这个容器来部署代码。 Docker 可以快速创建容器，快速迭代应用程序，并让整个过程全程可见，使团队中的其他成员更容易理解应用程序是如何创建和工作的。 Docker 容器很轻很快！容器的启动时间是秒级的，大量地节约开发、测试、部署的时间。 2、更高效的虚拟化 Docker 容器的运行不需要额外的 hypervisor 支持，它是内核级的虚拟化，因此可以实现更高的性能和效率。 3、更轻松的迁移和扩展 Docker 容器几乎可以在任意的平台上运行，包括物理机、虚拟机、公有云、私有云、个人电脑、服务器等。 这种兼容性可以让用户把一个应用程序从一个平台直接迁移到另外一个。 4、更简单的管理 使用 Docker，只需要小小的修改，就可以替代以往大量的更新工作。所有的修改都以增量的方式被分发和更新，从而实现自动化并且高效的管理。 Docker vs VM从下图可以看出，VM是一个运行在宿主机之上的完整的操作系统，VM运行自身操作系统会占用较多的CPU、内存、硬盘资源。Docker不同于VM，只包含应用程序以及依赖库，基于libcontainer运行在宿主机上，并处于一个隔离的环境中，这使得Docker更加轻量高效，启动容器只需几秒钟之内完成。由于Docker轻量、资源占用少，使得Docker可以轻易的应用到构建标准化的应用中。但Docker目前还不够完善，比如隔离效果不如VM，共享宿主机操作系统的一些基础库等；网络配置功能相对简单，主要以桥接方式为主；查看日志也不够方便灵活。 Docker 在容器的基础上，进行了进一步的封装，从文件系统、网络互联到进程隔离等等，极大的简化了容器的创建和维护。使得 Docker 技术比虚拟机技术更为轻便、快捷。 作为一种新兴的虚拟化方式，Docker 跟传统的虚拟化方式相比具有众多的优势。Docker 容器的启动可以在秒级实现，这相比传统的虚拟机方式要快得多；Docker 对系统资源的利用率很高，一台主机上可以同时运行数千个 Docker 容器。 相关概念Docker是CS架构，主要有两个概念： Docker daemon: 运行在宿主机上，Docker守护进程，用户通过Docker client(Docker命令)与Docker daemon交互 Docker client: Docker 命令行工具，是用户使用Docker的主要方式，Docker client与Docker daemon通信并将结果返回给用户，Docker client也可以通过socket或者RESTful api访问远程的Docker daemon 了解了Docker的组成，再来了解一下Docker的三个主要概念： Docker image：镜像是只读的，镜像中包含有需要运行的文件。镜像用来创建container，一个镜像可以运行多个container；镜像可以通过Dockerfile创建，也可以从Docker hub/registry上下载。 Docker container：容器是Docker的运行组件，启动一个镜像就是一个容器，容器是一个隔离环境，多个容器之间不会相互影响，保证容器中的程序运行在一个相对安全的环境中。 Docker hub/registry: 共享和管理Docker镜像，用户可以上传或者下载上面的镜像，官方地址为https://registry.hub.docker.com/，也可以搭建自己私有的Docker registry。 镜像就相当于打包好的版本，镜像启动之后运行在容器中，仓库就是装存储镜像的地方。 Docker安装建议在linux环境下安装Docker，window环境搭建比较复杂且容易出错，使用Centos7+yum来安装Docker环境很方便。 Docker 软件包已经包括在默认的 CentOS-Extras 软件源里。因此想要安装 docker，只需要运行下面的 yum 命令： 1yum install docker 安装完成后，使用下面的命令来启动 docker 服务，并将其设置为开机启动： 12service docker startchkconfig docker on LCTT 译注：此处采用了旧式的 sysv 语法，如采用CentOS 7中支持的新式 systemd 语法，如下： 12systemctl start docker.servicesystemctl enable docker.service 测试 1docker version 输入上述命令，返回docker的版本相关信息，证明docker安装成功。 Hello World下面，我们通过最简单的 image 文件”hello world”，感受一下 Docker。 因为国内连接 Docker 的官方仓库很慢，因此我们在日常使用中会使用Docker 中国加速器。通过 Docker 官方镜像加速，中国区用户能够快速访问最流行的 Docker 镜像。该镜像托管于中国大陆，本地用户现在将会享受到更快的下载速度和更强的稳定性，从而能够更敏捷地开发和交付 Docker 化应用。 Docker 中国官方镜像加速可通过registry.docker-cn.com访问。该镜像库只包含流行的公有镜像，私有镜像仍需要从美国镜像库中拉取。 修改系统中docker对应的配置文件即可，如下： 123456vi /etc/docker/daemon.json#添加后&#123; &quot;registry-mirrors&quot;: [&quot;https://registry.docker-cn.com&quot;], &quot;live-restore&quot;: true&#125; 运行下面的命令，将 image 文件从仓库抓取到本地。 1docker pull library/hello-world 上面代码中，docker image pull是抓取 image 文件的命令。library/hello-world是 image 文件在仓库里面的位置，其中library是 image 文件所在的组，hello-world是 image 文件的名字。 抓取成功以后，就可以在本机看到这个 image 文件了。 1234docker images#显示结果REPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/hello-world latest f2a91732366c 3 months ago 1.848 kB 现在，运行这个 image 文件。 123456docker run hello-world#显示结果Hello from Docker!This message shows that your installation appears to be working correctly.... 输出这段提示以后，hello world就会停止运行，容器自动终止。有些容器不会自动终止，因为提供的是服务，比如Mysql镜像等。 常用命令除过以上我们使用的Docker命令外，Docker还有一些其它常用的命令 拉取docker镜像 1docker pull image_name 查看宿主机上的镜像，Docker镜像保存在/var/lib/docker目录下: 1docker images 删除镜像 1docker rmi docker.io/tomcat:7.0.77-jre7 或者 docker rmi b39c68b7af30 查看当前有哪些容器正在运行 1docker ps 查看所有容器 1docker ps -a 启动、停止、重启容器命令： 123docker start container_name/container_iddocker stop container_name/container_iddocker restart container_name/container_id 后台启动一个容器后，如果想进入到这个容器，可以使用attach命令： 1docker attach container_name/container_id 删除容器的命令： 1docker rm container_name/container_id 删除所有停止的容器： 1docker rm $(docker ps -a -q) 查看当前系统Docker信息 1docker info 从Docker hub上下载某个镜像: 12docker pull centos:latestdocker pull centos:latest 查找Docker Hub上的nginx镜像 1docker search nginx 执行docker pull centos会将Centos这个仓库下面的所有镜像下载到本地repository。 参考Docker — 从入门到实践Docker系列之一：入门介绍Docker 入门教程 作者： 纯洁的微笑-ityouknow 链接：http://www.ityouknow.com/docker/2018/03/07/docker-introduction.html 来源：本文版权归作者，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。","categories":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/categories/Docker/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"单机部署 ELK","slug":"单机部署 ELK","date":"2019-03-26T16:00:00.000Z","updated":"2019-03-27T10:42:49.826Z","comments":true,"path":"2019/03/27/单机部署 ELK/","link":"","permalink":"http://yoursite.com/2019/03/27/单机部署 ELK/","excerpt":"","text":"对于一个体量不大的系统，运行在单机上的 ELK 就足以胜任日志的处理任务了。本文介绍如何在单台服务器上安装并配置 ELK(elalasticsearch + logstash + kibana)，并最终通过 filebeat 把日志数据发送给日志服务器(ELK)。整体的架构如下图所示(此图来自互联网)： 本文的演示环境为 Ubuntu Server 18.04，ELK 和 filebeat 的版本都是 6.2.4。 安装 java 运行时我们假设您已经有一台运行 Ubuntu Server 18.04 的主机了，所以安装步骤从 java 运行时开始。必须安装 java 运行时是因为 elasticsearch 和 logstash 都是 Java 程序。下面的命令安装 openjdk8： 12$ apt update$ apt install -y openjdk-8-jre-headless 安装完成后检查一下安装结果： 1$ java -version 安装 elasticsearch可以通过下面的命令安装 elasticsearch 6.2.4： 123456$ wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -$ sudo echo &quot;deb https://artifacts.elastic.co/packages/6.x/apt stable main&quot; | sudo tee -a /etc/apt/sources.list.d/elastic-6.x.list$ sudo apt update$ sudo apt install -y elasticsearch=6.2.4$ sudo systemctl daemon-reload$ sudo systemctl enable elasticsearch.service 安装 kibana可以通过下面的命令安装 kibana 6.2.4： 123456$ wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -$ sudo echo &quot;deb https://artifacts.elastic.co/packages/6.x/apt stable main&quot; | tee -a /etc/apt/sources.list.d/elastic-6.x.list$ sudo apt update$ sudo apt install -y kibana=6.2.4$ sudo systemctl daemon-reload$ sudo systemctl enable kibana.service 安装 logstash笔者在通过上面的方式安装 logstash 6.2.4 的时候发生了错误，说是找不到 logstash 6.2.4： 所以直接从官网下载了 6.2.4 的安装包通过下面的命令进行本地安装： 1234$ sudo apt install ./logstash-6.2.4.deb$ sudo systemctl daemon-reload$ sudo systemctl enable logstash.service 完整的安装脚本可以通过下面的脚本一次完成 elasticsearch、kibana 和 logstash 的安装： 123456789101112131415161718#!/bin/bash# sudo ./installelk6.2.4.u1804.sh apt updateapt install -y openjdk-8-jre-headlesswget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | apt-key add -echo &quot;deb https://artifacts.elastic.co/packages/6.x/apt stable main&quot; | tee -a /etc/apt/sources.list.d/elastic-6.x.listapt updateapt install -y elasticsearch=6.2.4apt install -y kibana=6.2.4apt install -y ./logstash-6.2.4.deb systemctl daemon-reloadsystemctl enable elasticsearch.servicesystemctl enable logstash.servicesystemctl enable kibana.service 把上面的内容保存在 installelk6.2.4.u1804.sh 文件中，和下载的 logstash-6.2.4.deb 文件放在同一个目录下，并进入到该目录中，执行下面的命令进行安装： 12$ chomd +x installelk6.2.4.u1804.sh$ sudo ./installelk6.2.4.u1804.sh 为 elasticsearch 挂载一个大磁盘elasticsearch 需要大容量的存储设备来保存日志数据，所以我们这里单独添加一块 1T 的磁盘来保存日志数据。先在系统的根目录下创建 esdata 目录作为磁盘的挂载点，elasticsearch 中的数据和自身的日志将会保存到这个目录中： 1$ sudo mkdir /esdata 我们添加的磁盘的文件设备名称为 /dev/sdb，下面就把磁盘挂载到 /esdata 目录。先使用 fdisk 命令对磁盘进行分区： 1$ (echo n; echo p; echo 1; echo ; echo ; echo w) | sudo fdisk /dev/sdb 然后使用 mkfs 命令将文件系统写入分区： 1$ sudo mkfs -t ext4 /dev/sdb1 最后把新的磁盘分区挂载到 /esdata 装载新磁盘使其在操作系统中可访问： 1$ sudo mount /dev/sdb1 /esdata 查看挂载完成后的文件系统： 1$ df -h 接下来设置 elasticsearch 用户作为该目录的所有者，这样就 elasticsearch 就能往目录下写文件了： 12$ sudo chown elasticsearch:elasticsearch /esdata$ sudo chmod 750 /esdata 设置开机自动挂载 现在挂载的文件系统 /esdata 会在系统重启后丢掉，因此需要设置在开机时自动挂载这个文件系统。先通过下面的命令找到设备的 UUID： 1$sudo -i blkid 输出的内容为类似于下面的一些行，其中的 UUID 是我们需要的： 1/dev/sdb1: UUID=&quot;db048fa3-903b-4b85-a7ab-01c920283eeb&quot; TYPE=&quot;ext4&quot; PARTUUID=&quot;b0261bed-01&quot; 在 /etc/fstab 文件中添加类似于以下内容的行，其中的 UUID 就是从上面得来的： 1UUID=db048fa3-903b-4b85-a7ab-01c920283eeb /esdata ext4 defaults,nofail,barrier=0 1 2 这样的设置完成后，文件系统会在开机时自动挂载。 修改 elasticsearch 数据和日志文件的存储位置在 /etc/elasticsearch/elasticsearch.yml 文件中找 path.data 和 path.logs 的设置，并修改如下： 123456# ----------------------------------- Paths ------------------------------------# Path to directory where to store the data (separate multiple locations by comma):path.data: /esdata## Path to log files:path.logs: /esdata 配置 kibanakibana 服务默认监听的端口号修为 5601，但是默认只有在本机才能访问！要取消对访问者 IP 地址的限制，需要修改配置文件 /etc/kibana/kibana.yml 中的 server.host，把默认值 localhost 改为 0.0.0.0: 12#server.host: &quot;localhost&quot;server.host: &quot;0.0.0.0&quot; 配置 logstashlogstash 的配置文件为 /etc/logstash/logstash.yml 默认不需要修改。在 /etc/logstash/conf.d 目录下添加配置文件 beat2es.conf，内容如下： 12345678910111213input&#123; beats&#123; port =&gt; 5044 &#125;&#125;output &#123; elasticsearch &#123; hosts =&gt; [&quot;localhost:9200&quot;] index =&gt; &quot;beat-test-%&#123;+YYYY.MM.dd&#125;&quot; sniffing =&gt; true template_overwrite =&gt; true &#125;&#125; 该配置会让 logstash 服务监听 5044 端口接收数据： 1*:5044 到此为止，我们已经完成了 elasticsearch、kibana 和 logstash 的安装和配置，下面启动这些服务： 123$ sudo systemctl start elasticsearch.service$ sudo systemctl start kibana.service$ sudo systemctl start logstash.service 安装 filebeat假设我们也在 Ubuntu Server 18.04 的环境中安装 filebeat 6.2.4。先从官网下载 filebeat 6.2.4 deb 包，或者直接运行下面的命令进行安装： 1234$ curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-6.2.4-amd64.deb$ sudo dpkg -i ./filebeat-6.2.4-amd64.deb$ sudo systemctl daemon-reload$ sudo systemctl enable filebeat.service 验证安装： 12$ filebeat versionfilebeat version 6.2.4 (amd64), libbeat 6.2.4 配置 filebeat配置 filebeat 从文件收集日志编辑配置文件 /etc/filebeat/filebeat.yml，在 filebeat.prospectors 段修改 type 为 log 中的内容： 123456- type: log # Change to true to enable this prospector configuration. enabled: true # Paths that should be crawled and fetched. Glob based paths. paths: - /home/nick/work/test.log 把日志发送给 logstash编辑配置文件 /etc/filebeat/filebeat.yml，在 output.logstash 段修改配置 中的内容： 123output.logstash: # The Logstash hosts hosts: [&quot;your log server ip:5044&quot;] 多行事件编码(合并多行到一条记录)在 filebeat.prospectors 配置块中添加下面的配置： 1234### Multiline optionsmultiline.pattern: &apos;^\\[&apos;multiline.negate: truemultiline.match: after 注释掉 output.elasticsearch同时要把 output.elasticsearch 的配置注释掉。 123#output.elasticsearch: # Array of hosts to connect to. #hosts: [&quot;localhost:9200&quot;] 最后启动 filebeat 服务： 1$ sudo systemctl start filebeat.service 测试一下通过 echo 向 /home/nick/work/test.log 文件中追加 ‘[‘ 开头的行模拟日志记录： 1234echo &quot;[exception:]&quot; &gt;&gt; work/test.logecho &quot; at xxx&quot; &gt;&gt; work/test.logecho &quot; at xxx&quot; &gt;&gt; work/test.logecho &quot;[OK]&quot; &gt;&gt; work/test.log “ at” 开头的行用来模拟程序中的异常堆栈。 在浏览器中打开 kibana，添加 beat-test* 模式的索引就可以看到日志记录了： 由于我们在 filebeat 的配置中设置了 multiline 处理，所以类似 “ at” 开头的行会被认为是异常堆栈从而合并到一条记录中： 这样的设置在故障调查时会让异常堆栈看起来更友好些！ 总结ELK 本身是个体量比较大的日志系统(当然也可以用来干其它的事情)，安装和配置都会有些坑。本文只是介绍如何部署一个袖珍的 demo 环境，方便大家开始了解和学习 ELK。 作者：sparkdev 链接：http://www.cnblogs.com/sparkdev/ 来源：本文版权归作者和博客园共有，欢迎转载，但未经作者同意必须保留此段声明，且在文章页面明显位置给出原文连接，否则保留追究法律责任的权利。","categories":[{"name":"elk","slug":"elk","permalink":"http://yoursite.com/categories/elk/"}],"tags":[{"name":"elk","slug":"elk","permalink":"http://yoursite.com/tags/elk/"}]},{"title":"分布式锁之Redis实现","slug":"分布式锁之Redis实现","date":"2019-03-25T16:00:00.000Z","updated":"2019-03-26T08:30:35.962Z","comments":true,"path":"2019/03/26/分布式锁之Redis实现/","link":"","permalink":"http://yoursite.com/2019/03/26/分布式锁之Redis实现/","excerpt":"","text":"在Java中，关于锁我想大家都很熟悉。在并发编程中，我们通过锁，来避免由于竞争而造成的数据不一致问题。通常，我们以synchronized 、Lock来使用它。 但是Java中的锁，只能保证在同一个JVM进程内中执行。如果在分布式集群环境下呢？ 一、分布式锁分布式锁，是一种思想，它的实现方式有很多。比如，我们将沙滩当做分布式锁的组件，那么它看起来应该是这样的： 加锁 在沙滩上踩一脚，留下自己的脚印，就对应了加锁操作。其他进程或者线程，看到沙滩上已经有脚印，证明锁已被别人持有，则等待。 解锁 把脚印从沙滩上抹去，就是解锁的过程。 锁超时 为了避免死锁，我们可以设置一阵风，在单位时间后刮起，将脚印自动抹去。 分布式锁的实现有很多，比如基于数据库、memcached、Redis、系统文件、zookeeper等。它们的核心的理念跟上面的过程大致相同。 二、redis我们先来看如何通过单节点Redis实现一个简单的分布式锁。 1、加锁加锁实际上就是在redis中，给Key键设置一个值，为避免死锁，并给定一个过期时间。 1SET lock_key random_value NX PX 5000 值得注意的是： random_value 是客户端生成的唯一的字符串。 NX 代表只在键不存在时，才对键进行设置操作。 PX 5000 设置键的过期时间为5000毫秒。 这样，如果上面的命令执行成功，则证明客户端获取到了锁。 2、解锁解锁的过程就是将Key键删除。但也不能乱删，不能说客户端1的请求将客户端2的锁给删除掉。这时候random_value的作用就体现出来。 为了保证解锁操作的原子性，我们用LUA脚本完成这一操作。先判断当前锁的字符串是否与传入的值相等，是的话就删除Key，解锁成功。 12345if redis.call(&apos;get&apos;,KEYS[1]) == ARGV[1] then return redis.call(&apos;del&apos;,KEYS[1]) else return 0 end 3、实现首先，我们在pom文件中，引入Jedis。在这里，笔者用的是最新版本，注意由于版本的不同，API可能有所差异。 12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.0.1&lt;/version&gt;&lt;/dependency&gt; 加锁的过程很简单，就是通过SET指令来设置值，成功则返回；否则就循环等待，在timeout时间内仍未获取到锁，则获取失败。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@Servicepublic class RedisLock &#123; Logger logger = LoggerFactory.getLogger(this.getClass()); private String lock_key = &quot;redis_lock&quot;; //锁键 protected long internalLockLeaseTime = 30000;//锁过期时间 private long timeout = 999999; //获取锁的超时时间 //SET命令的参数 SetParams params = SetParams.setParams().nx().px(internalLockLeaseTime); @Autowired JedisPool jedisPool; /** * 加锁 * @param id * @return */ public boolean lock(String id)&#123; Jedis jedis = jedisPool.getResource(); Long start = System.currentTimeMillis(); try&#123; for(;;)&#123; //SET命令返回OK ，则证明获取锁成功 String lock = jedis.set(lock_key, id, params); if(&quot;OK&quot;.equals(lock))&#123; return true; &#125; //否则循环等待，在timeout时间内仍未获取到锁，则获取失败 long l = System.currentTimeMillis() - start; if (l&gt;=timeout) &#123; return false; &#125; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;finally &#123; jedis.close(); &#125; &#125;&#125; 解锁我们通过jedis.eval来执行一段LUA就可以。将锁的Key键和生成的字符串当做参数传进来。 123456789101112131415161718192021222324/** * 解锁 * @param id * @return */ public boolean unlock(String id)&#123; Jedis jedis = jedisPool.getResource(); String script = &quot;if redis.call(&apos;get&apos;,KEYS[1]) == ARGV[1] then&quot; + &quot; return redis.call(&apos;del&apos;,KEYS[1]) &quot; + &quot;else&quot; + &quot; return 0 &quot; + &quot;end&quot;; try &#123; Object result = jedis.eval(script, Collections.singletonList(lock_key), Collections.singletonList(id)); if(&quot;1&quot;.equals(result.toString()))&#123; return true; &#125; return false; &#125;finally &#123; jedis.close(); &#125; &#125; 最后，我们可以在多线程环境下测试一下。我们开启1000个线程，对count进行累加。调用的时候，关键是唯一字符串的生成。这里，笔者使用的是Snowflake算法。 12345678910111213141516171819202122232425262728293031323334353637@Controllerpublic class IndexController &#123; @Autowired RedisLock redisLock; int count = 0; @RequestMapping(&quot;/index&quot;) @ResponseBody public String index() throws InterruptedException &#123; int clientcount =1000; CountDownLatch countDownLatch = new CountDownLatch(clientcount); ExecutorService executorService = Executors.newFixedThreadPool(clientcount); long start = System.currentTimeMillis(); for (int i = 0;i&lt;clientcount;i++)&#123; executorService.execute(() -&gt; &#123; //通过Snowflake算法获取唯一的ID字符串 String id = IdUtil.getId(); try &#123; redisLock.lock(id); count++; &#125;finally &#123; redisLock.unlock(id); &#125; countDownLatch.countDown(); &#125;); &#125; countDownLatch.await(); long end = System.currentTimeMillis(); logger.info(&quot;执行线程数:&#123;&#125;,总耗时:&#123;&#125;,count数为:&#123;&#125;&quot;,clientcount,end-start,count); return &quot;Hello&quot;; &#125;&#125; 至此，单节点Redis的分布式锁的实现就已经完成了。比较简单，但是问题也比较大，最重要的一点是，锁不具有可重入性。 三、redisson Redisson是架设在Redis基础上的一个Java驻内存数据网格（In-Memory Data Grid）。充分的利用了Redis键值数据库提供的一系列优势，基于Java实用工具包中常用接口，为使用者提供了一系列具有分布式特性的常用工具类。使得原本作为协调单机多线程并发程序的工具包获得了协调分布式多机多线程并发系统的能力，大大降低了设计和研发大规模分布式系统的难度。同时结合各富特色的分布式服务，更进一步简化了分布式环境中程序相互之间的协作。 相对于Jedis而言，Redisson强大的一批。当然了，随之而来的就是它的复杂性。它里面也实现了分布式锁，而且包含多种类型的锁，更多请参阅分布式锁和同步器 1、可重入锁上面我们自己实现的Redis分布式锁，其实不具有可重入性。那么下面我们先来看看Redisson中如何调用可重入锁。 在这里，笔者使用的是它的最新版本，3.10.1。 12345&lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.10.1&lt;/version&gt;&lt;/dependency&gt; 首先，通过配置获取RedissonClient客户端的实例，然后getLock获取锁的实例，进行操作即可。 123456789101112131415public static void main(String[] args) &#123; Config config = new Config(); config.useSingleServer().setAddress(&quot;redis://127.0.0.1:6379&quot;); config.useSingleServer().setPassword(&quot;redis1234&quot;); final RedissonClient client = Redisson.create(config); RLock lock = client.getLock(&quot;lock1&quot;); try&#123; lock.lock(); &#125;finally&#123; lock.unlock(); &#125;&#125; 2、获取锁实例我们先来看RLock lock = client.getLock(&quot;lock1&quot;); 这句代码就是为了获取锁的实例，然后我们可以看到它返回的是一个RedissonLock对象。 1234public RLock getLock(String name) &#123; return new RedissonLock(connectionManager.getCommandExecutor(), name);&#125;复制代码 在RedissonLock构造方法中，主要初始化一些属性。 1234567891011public RedissonLock(CommandAsyncExecutor commandExecutor, String name) &#123; super(commandExecutor, name); //命令执行器 this.commandExecutor = commandExecutor; //UUID字符串 this.id = commandExecutor.getConnectionManager().getId(); //内部锁过期时间 this.internalLockLeaseTime = commandExecutor. getConnectionManager().getCfg().getLockWatchdogTimeout(); this.entryName = id + &quot;:&quot; + name;&#125; 3、加锁当我们调用lock方法，定位到lockInterruptibly。在这里，完成了加锁的逻辑。 1234567891011121314151617181920212223242526272829303132333435public void lockInterruptibly(long leaseTime, TimeUnit unit) throws InterruptedException &#123; //当前线程ID long threadId = Thread.currentThread().getId(); //尝试获取锁 Long ttl = tryAcquire(leaseTime, unit, threadId); // 如果ttl为空，则证明获取锁成功 if (ttl == null) &#123; return; &#125; //如果获取锁失败，则订阅到对应这个锁的channel RFuture&lt;RedissonLockEntry&gt; future = subscribe(threadId); commandExecutor.syncSubscription(future); try &#123; while (true) &#123; //再次尝试获取锁 ttl = tryAcquire(leaseTime, unit, threadId); //ttl为空，说明成功获取锁，返回 if (ttl == null) &#123; break; &#125; //ttl大于0 则等待ttl时间后继续尝试获取 if (ttl &gt;= 0) &#123; getEntry(threadId).getLatch().tryAcquire(ttl, TimeUnit.MILLISECONDS); &#125; else &#123; getEntry(threadId).getLatch().acquire(); &#125; &#125; &#125; finally &#123; //取消对channel的订阅 unsubscribe(future, threadId); &#125; //get(lockAsync(leaseTime, unit));&#125; 如上代码，就是加锁的全过程。先调用tryAcquire来获取锁，如果返回值ttl为空，则证明加锁成功，返回；如果不为空，则证明加锁失败。这时候，它会订阅这个锁的Channel，等待锁释放的消息，然后重新尝试获取锁。流程如下： 获取锁 获取锁的过程是怎样的呢？接下来就要看tryAcquire方法。在这里，它有两种处理方式，一种是带有过期时间的锁，一种是不带过期时间的锁。 1234567891011121314151617181920212223242526272829private &lt;T&gt; RFuture&lt;Long&gt; tryAcquireAsync(long leaseTime, TimeUnit unit, final long threadId) &#123; //如果带有过期时间，则按照普通方式获取锁 if (leaseTime != -1) &#123; return tryLockInnerAsync(leaseTime, unit, threadId, RedisCommands.EVAL_LONG); &#125; //先按照30秒的过期时间来执行获取锁的方法 RFuture&lt;Long&gt; ttlRemainingFuture = tryLockInnerAsync( commandExecutor.getConnectionManager().getCfg().getLockWatchdogTimeout(), TimeUnit.MILLISECONDS, threadId, RedisCommands.EVAL_LONG); //如果还持有这个锁，则开启定时任务不断刷新该锁的过期时间 ttlRemainingFuture.addListener(new FutureListener&lt;Long&gt;() &#123; @Override public void operationComplete(Future&lt;Long&gt; future) throws Exception &#123; if (!future.isSuccess()) &#123; return; &#125; Long ttlRemaining = future.getNow(); // lock acquired if (ttlRemaining == null) &#123; scheduleExpirationRenewal(threadId); &#125; &#125; &#125;); return ttlRemainingFuture;&#125; 接着往下看，tryLockInnerAsync方法是真正执行获取锁的逻辑，它是一段LUA脚本代码。在这里，它使用的是hash数据结构。 123456789101112131415161718192021222324&lt;T&gt; RFuture&lt;T&gt; tryLockInnerAsync(long leaseTime, TimeUnit unit, long threadId, RedisStrictCommand&lt;T&gt; command) &#123; //过期时间 internalLockLeaseTime = unit.toMillis(leaseTime); return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, command, //如果锁不存在，则通过hset设置它的值，并设置过期时间 &quot;if (redis.call(&apos;exists&apos;, KEYS[1]) == 0) then &quot; + &quot;redis.call(&apos;hset&apos;, KEYS[1], ARGV[2], 1); &quot; + &quot;redis.call(&apos;pexpire&apos;, KEYS[1], ARGV[1]); &quot; + &quot;return nil; &quot; + &quot;end; &quot; + //如果锁已存在，并且锁的是当前线程，则通过hincrby给数值递增1 &quot;if (redis.call(&apos;hexists&apos;, KEYS[1], ARGV[2]) == 1) then &quot; + &quot;redis.call(&apos;hincrby&apos;, KEYS[1], ARGV[2], 1); &quot; + &quot;redis.call(&apos;pexpire&apos;, KEYS[1], ARGV[1]); &quot; + &quot;return nil; &quot; + &quot;end; &quot; + //如果锁已存在，但并非本线程，则返回过期时间ttl &quot;return redis.call(&apos;pttl&apos;, KEYS[1]);&quot;, Collections.&lt;Object&gt;singletonList(getName()), internalLockLeaseTime, getLockName(threadId)); &#125; 这段LUA代码看起来并不复杂，有三个判断： 通过exists判断，如果锁不存在，则设置值和过期时间，加锁成功 通过hexists判断，如果锁已存在，并且锁的是当前线程，则证明是重入锁，加锁成功 如果锁已存在，但锁的不是当前线程，则证明有其他线程持有锁。返回当前锁的过期时间，加锁失败 加锁成功后，在redis的内存数据中，就有一条hash结构的数据。Key为锁的名称；field为随机字符串+线程ID；值为1。如果同一线程多次调用lock方法，值递增1。 123127.0.0.1:6379&gt; hgetall lock11) \"b5ae0be4-5623-45a5-8faa-ab7eb167ce87:1\"2) \"1\" 4、解锁我们通过调用unlock方法来解锁。 1234567891011121314151617181920212223242526272829303132333435public RFuture&lt;Void&gt; unlockAsync(final long threadId) &#123; final RPromise&lt;Void&gt; result = new RedissonPromise&lt;Void&gt;(); //解锁方法 RFuture&lt;Boolean&gt; future = unlockInnerAsync(threadId); future.addListener(new FutureListener&lt;Boolean&gt;() &#123; @Override public void operationComplete(Future&lt;Boolean&gt; future) throws Exception &#123; if (!future.isSuccess()) &#123; cancelExpirationRenewal(threadId); result.tryFailure(future.cause()); return; &#125; //获取返回值 Boolean opStatus = future.getNow(); //如果返回空，则证明解锁的线程和当前锁不是同一个线程，抛出异常 if (opStatus == null) &#123; IllegalMonitorStateException cause = new IllegalMonitorStateException(&quot; attempt to unlock lock, not locked by current thread by node id: &quot; + id + &quot; thread-id: &quot; + threadId); result.tryFailure(cause); return; &#125; //解锁成功，取消刷新过期时间的那个定时任务 if (opStatus) &#123; cancelExpirationRenewal(null); &#125; result.trySuccess(null); &#125; &#125;); return result;&#125; 然后我们再看unlockInnerAsync方法。这里也是一段LUA脚本代码。 1234567891011121314151617181920212223242526272829protected RFuture&lt;Boolean&gt; unlockInnerAsync(long threadId) &#123; return commandExecutor.evalWriteAsync(getName(), LongCodec.INSTANCE, EVAL, //如果锁已经不存在， 发布锁释放的消息 &quot;if (redis.call(&apos;exists&apos;, KEYS[1]) == 0) then &quot; + &quot;redis.call(&apos;publish&apos;, KEYS[2], ARGV[1]); &quot; + &quot;return 1; &quot; + &quot;end;&quot; + //如果释放锁的线程和已存在锁的线程不是同一个线程，返回null &quot;if (redis.call(&apos;hexists&apos;, KEYS[1], ARGV[3]) == 0) then &quot; + &quot;return nil;&quot; + &quot;end; &quot; + //通过hincrby递减1的方式，释放一次锁 //若剩余次数大于0 ，则刷新过期时间 &quot;local counter = redis.call(&apos;hincrby&apos;, KEYS[1], ARGV[3], -1); &quot; + &quot;if (counter &gt; 0) then &quot; + &quot;redis.call(&apos;pexpire&apos;, KEYS[1], ARGV[2]); &quot; + &quot;return 0; &quot; + //否则证明锁已经释放，删除key并发布锁释放的消息 &quot;else &quot; + &quot;redis.call(&apos;del&apos;, KEYS[1]); &quot; + &quot;redis.call(&apos;publish&apos;, KEYS[2], ARGV[1]); &quot; + &quot;return 1; &quot;+ &quot;end; &quot; + &quot;return nil;&quot;, Arrays.&lt;Object&gt;asList(getName(), getChannelName()), LockPubSub.unlockMessage, internalLockLeaseTime, getLockName(threadId));&#125; 如上代码，就是释放锁的逻辑。同样的，它也是有三个判断： 如果锁已经不存在，通过publish发布锁释放的消息，解锁成功 如果解锁的线程和当前锁的线程不是同一个，解锁失败，抛出异常 通过hincrby递减1，先释放一次锁。若剩余次数还大于0，则证明当前锁是重入锁，刷新过期时间；若剩余次数小于0，删除key并发布锁释放的消息，解锁成功 至此，Redisson中的可重入锁的逻辑，就分析完了。但值得注意的是，上面的两种实现方式都是针对单机Redis实例而进行的。如果我们有多个Redis实例，请参阅Redlock算法。该算法的具体内容，请参考redis.cn/topics/dist… 作者：清幽之地 链接：https://juejin.im/post/5c6e25aaf265da2dc538b4f9 来源：掘金 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[{"name":"分布式锁","slug":"分布式锁","permalink":"http://yoursite.com/categories/分布式锁/"}],"tags":[{"name":"分布式锁","slug":"分布式锁","permalink":"http://yoursite.com/tags/分布式锁/"}]},{"title":"Java内存模型深度剖析","slug":"Java内存模型深度剖析","date":"2019-03-07T16:00:00.000Z","updated":"2019-03-26T08:32:11.888Z","comments":true,"path":"2019/03/08/Java内存模型深度剖析/","link":"","permalink":"http://yoursite.com/2019/03/08/Java内存模型深度剖析/","excerpt":"","text":"为什么要有内存模型 在介绍Java内存模型之前，先来看一下到底什么是计算机内存模型，然后再来看Java内存模型在计算机内存模型的基础上做了哪些事情。要说计算机的内存模型，就要说一下一段古老的历史，看一下为什么要有内存模型。 内存模型，英文名Memory Model，他是一个很老的老古董了。他是与计算机硬件有关的一个概念。那么我先给你介绍下他和硬件到底有啥关系。 CPU和缓存一致性我们应该都知道，计算机在执行程序的时候，每条指令都是在CPU中执行的，而执行的时候，又免不了要和数据打交道。而计算机上面的数据，是存放在主存当中的，也就是计算机的物理内存啦。 刚开始，还相安无事的，但是随着CPU技术的发展，CPU的执行速度越来越快。而由于内存的技术并没有太大的变化，所以从内存中读取和写入数据的过程和CPU的执行速度比起来差距就会越来越大,这就导致CPU每次操作内存都要耗费很多等待时间。 这就像一家创业公司，刚开始，创始人和员工之间工作关系其乐融融，但是随着创始人的能力和野心越来越大，逐渐和员工之间出现了差距，普通员工原来越跟不上CEO的脚步。老板的每一个命令，传到到基层员工之后，由于基层员工的理解能力、执行能力的欠缺，就会耗费很多时间。这也就无形中拖慢了整家公司的工作效率。 可是，不能因为内存的读写速度慢，就不发展CPU技术了吧，总不能让内存成为计算机处理的瓶颈吧。 所以，人们想出来了一个好的办法，就是在CPU和内存之间增加高速缓存。缓存的概念大家都知道，就是保存一份数据拷贝。他的特点是速度快，内存小，并且昂贵。 那么，程序的执行过程就变成了： 当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。 之后，这家公司开始设立中层管理人员，管理人员直接归CEO领导，领导有什么指示，直接告诉管理人员，然后就可以去做自己的事情了。管理人员负责去协调底层员工的工作。因为管理人员是了解手下的人员以及自己负责的事情的。所以，大多数时候，公司的各种决策，通知等，CEO只要和管理人员之间沟通就够了。 而随着CPU能力的不断提升，一层缓存就慢慢的无法满足要求了，就逐渐的衍生出多级缓存。 按照数据读取顺序和与CPU结合的紧密程度，CPU缓存可以分为一级缓存（L1），二级缓存（L3），部分高端CPU还具有三级缓存（L3），每一级缓存中所储存的全部数据都是下一级缓存的一部分。 这三种缓存的技术难度和制造成本是相对递减的，所以其容量也是相对递增的。 那么，在有了多级缓存之后，程序的执行就变成了： 当CPU要读取一个数据时，首先从一级缓存中查找，如果没有找到再从二级缓存中查找，如果还是没有就从三级缓存或内存中查找。 随着公司越来越大，老板要管的事情越来越多，公司的管理部门开始改革，开始出现高层，中层，底层等管理者。一级一级之间逐层管理。 单核CPU只含有一套L1，L2，L3缓存； 如果CPU含有多个核心，即多核CPU，则每个核心都含有一套L1（甚至和L2）缓存，而共享L3（或者和L2）缓存。 公司也分很多种，有些公司只有一个大Boss，他一个人说了算。但是有些公司有比如联席总经理、合伙人等机制。 单核CPU就像一家公司只有一个老板，所有命令都来自于他，那么就只需要一套管理班底就够了。 多核CPU就像一家公司是由多个合伙人共同创办的，那么，就需要给每个合伙人都设立一套供自己直接领导的高层管理人员，多个合伙人共享使用的是公司的底层员工。 还有的公司，不断壮大，开始差分出各个子公司。各个子公司就是多个CPU了，互相之前没有共用的资源。互不影响。 下图为一个单CPU双核的缓存结构。 CACHE随着计算机能力不断提升，开始支持多线程。那么问题就来了。我们分别来分析下单线程、多线程在单核CPU、多核CPU中的影响。 单线程。cpu核心的缓存只被一个线程访问。缓存独占，不会出现访问冲突等问题。 单核CPU，多线程。进程中的多个线程会同时访问进程中的共享数据，CPU将某块内存加载到缓存后，不同线程在访问相同的物理地址的时候，都会映射到相同的缓存位置，这样即使发生线程的切换，缓存仍然不会失效。但由于任何时刻只能有一个线程在执行，因此不会出现缓存访问冲突。 多核CPU，多线程。每个核都至少有一个L1 缓存。多个线程访问进程中的某个共享内存，且这多个线程分别在不同的核心上执行，则每个核心都会在各自的caehe中保留一份共享内存的缓冲。由于多核是可以并行的，可能会出现多个线程同时写各自的缓存的情况，而各自的cache之间的数据就有可能不同。 在CPU和主存之间增加缓存，在多线程场景下就可能存在缓存一致性问题，也就是说，在多核CPU中，每个核的自己的缓存中，关于同一个数据的缓存内容可能不一致。 如果这家公司的命令都是串行下发的话，那么就没有任何问题。 如果这家公司的命令都是并行下发的话，并且这些命令都是由同一个CEO下发的，这种机制是也没有什么问题。因为他的命令执行者只有一套管理体系。 如果这家公司的命令都是并行下发的话，并且这些命令是由多个合伙人下发的，这就有问题了。因为每个合伙人只会把命令下达给自己直属的管理人员，而多个管理人员管理的底层员工可能是公用的。 比如，合伙人1要辞退员工a，合伙人2要给员工a升职，升职后的话他再被辞退需要多个合伙人开会决议。两个合伙人分别把命令下发给了自己的管理人员。合伙人1命令下达后，管理人员a在辞退了员工后，他就知道这个员工被开除了。而合伙人2的管理人员2这时候在没得到消息之前，还认为员工a是在职的，他就欣然的接收了合伙人给他的升职a的命令。 一致处理器优化和指令重排上面提到在在CPU和主存之间增加缓存，在多线程场景下会存在缓存一致性问题。除了这种情况，还有一种硬件问题也比较重要。那就是为了使处理器内部的运算单元能够尽量的被充分利用，处理器可能会对输入代码进行乱序执行处理。这就是处理器优化。 除了现在很多流行的处理器会对代码进行优化乱序处理，很多编程语言的编译器也会有类似的优化，比如Java虚拟机的即时编译器（JIT）也会做指令重排。 可想而知，如果任由处理器优化和编译器对指令重排的话，就可能导致各种各样的问题。 关于员工组织调整的情况，如果允许人事部在接到多个命令后进行随意拆分乱序执行或者重排的话，那么对于这个员工以及这家公司的影响是非常大的。 并发编程的问题 前面说的和硬件有关的概念你可能听得有点蒙，还不知道他到底和软件有啥关系。但是关于并发编程的问题你应该有所了解，比如原子性问题，可见性问题和有序性问题。 其实，原子性问题，可见性问题和有序性问题。是人们抽象定义出来的。而这个抽象的底层问题就是前面提到的缓存一致性问题、处理器优化问题和指令重排问题等。 这里简单回顾下这三个问题，并不准备深入展开，感兴趣的读者可以自行学习。我们说，并发编程，为了保证数据的安全，需要满足以下三个特性： 原子性是指在一个操作中就是cpu不可以在中途暂停然后再调度，既不被中断操作，要不执行完成，要不就不执行。 可见性是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。 有序性即程序执行的顺序按照代码的先后顺序执行。 有没有发现，缓存一致性问题其实就是可见性问题。而处理器优化是可以导致原子性问题的。指令重排即会导致有序性问题。所以，后文将不再提起硬件层面的那些概念，而是直接使用大家熟悉的原子性、可见性和有序性。 什么是内存模型 前面提到的，缓存一致性问题、处理器器优化的指令重排问题是硬件的不断升级导致的。那么，有没有什么机制可以很好的解决上面的这些问题呢？ 最简单直接的做法就是废除处理器和处理器的优化技术、废除CPU缓存，让CPU直接和主存交互。但是，这么做虽然可以保证多线程下的并发问题。但是，这就有点因噎废食了。 所以，为了保证并发编程中可以满足原子性、可见性及有序性。有一个重要的概念，那就是——内存模型。 为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范。通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性。它与处理器有关、与缓存有关、与并发有关、与编译器也有关。他解决了CPU多级缓存、处理器优化、指令重排等导致的内存访问问题，保证了并发场景下的一致性、原子性和有序性。 内存模型解决并发问题主要采用两种方式：限制处理器优化和使用内存屏障。本文就不深入底层原理来展开介绍了，感兴趣的朋友可以自行学习。 什么是Java内存模型 前面介绍过了计算机内存模型，这是解决多线程场景下并发问题的一个重要规范。那么具体的实现是如何的呢，不同的编程语言，在实现上可能有所不同。 我们知道，Java程序是需要运行在Java虚拟机上面的，Java内存模型（Java Memory Model ,JMM）就是一种符合内存模型规范的，屏蔽了各种硬件和操作系统的访问差异的，保证了Java程序在各种平台下对内存的访问都能保证效果一致的机制及规范。 提到Java内存模型，一般指的是JDK 5 开始使用的新的内存模型，主要由JSR-133: JavaTM Memory Model and Thread Specification 描述。感兴趣的可以参看下这份PDF文档（http://www.cs.umd.edu/~pugh/java/memoryModel/jsr133.pdf） Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。 而JMM就作用于工作内存和主存之间数据同步过程。他规定了如何做数据同步以及什么时候做数据同步。 JAVA这里面提到的主内存和工作内存，读者可以简单的类比成计算机内存模型中的主存和缓存的概念。特别需要注意的是，主内存和工作内存与JVM内存结构中的Java堆、栈、方法区等并不是同一个层次的内存划分，无法直接类比。《深入理解Java虚拟机》中认为，如果一定要勉强对应起来的话，从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分。工作内存则对应于虚拟机栈中的部分区域。 所以，再来总结下，JMM是一种规范，目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。目的是保证并发编程场景中的原子性、可见性和有序性。 Java内存模型的实现 了解Java多线程的朋友都知道，在Java中提供了一系列和并发处理相关的关键字，比如volatile、synchronized、final、concurren包等。其实这些就是Java内存模型封装了底层的实现后提供给程序员使用的一些关键字。 在开发多线程的代码的时候，我们可以直接使用synchronized等关键字来控制并发，从来就不需要关心底层的编译器优化、缓存一致性等问题。所以，Java内存模型，除了定义了一套规范，还提供了一系列原语，封装了底层实现后，供开发者直接使用。 本文并不准备把所有的关键字逐一介绍其用法，因为关于各个关键字的用法，网上有很多资料。读者可以自行学习。本文还有一个重点要介绍的就是，我们前面提到，并发编程要解决原子性、有序性和一致性的问题，我们就再来看下，在Java中，分别使用什么方式来保证。 原子性在Java中，为了保证原子性，提供了两个高级的字节码指令monitorenter和monitorexit。在synchronized的实现原理文章中，介绍过，这两个字节码，在Java中对应的关键字就是synchronized。 因此，在Java中可以使用synchronized来保证方法和代码块内的操作是原子性的。 可见性Java内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值的这种依赖主内存作为传递媒介的方式来实现的。 Java中的volatile关键字提供了一个功能，那就是被其修饰的变量在被修改后可以立即同步到主内存，被其修饰的变量在每次是用之前都从主内存刷新。因此，可以使用volatile来保证多线程操作时变量的可见性。 除了volatile，Java中的synchronized和final两个关键字也可以实现可见性。只不过实现方式不同，这里不再展开了。 有序性在Java中，可以使用synchronized和volatile来保证多线程之间操作的有序性。实现方式有所区别： volatile关键字会禁止指令重排。synchronized关键字保证同一时刻只允许一条线程操作。 好了，这里简单的介绍完了Java并发编程中解决原子性、可见性以及有序性可以使用的关键字。读者可能发现了，好像synchronized关键字是万能的，他可以同时满足以上三种特性，这其实也是很多人滥用synchronized的原因。 但是synchronized是比较影响性能的，虽然编译器提供了很多锁优化技术，但是也不建议过度使用。 总结 在读完本文之后，相信你应该了解了什么是Java内存模型、Java内存模型的作用以及Java中内存模型做了什么事情等。","categories":[{"name":"内存模型","slug":"内存模型","permalink":"http://yoursite.com/categories/内存模型/"}],"tags":[{"name":"内存模型","slug":"内存模型","permalink":"http://yoursite.com/tags/内存模型/"}]},{"title":"jdk1.8 线程池部分源码分析","slug":"jdk1.8 线程池部分源码分析","date":"2019-03-07T16:00:00.000Z","updated":"2019-03-26T08:32:14.607Z","comments":true,"path":"2019/03/08/jdk1.8 线程池部分源码分析/","link":"","permalink":"http://yoursite.com/2019/03/08/jdk1.8 线程池部分源码分析/","excerpt":"","text":"普通线程 1.实现：继承Thread或者实现Runnable接口 1.继承Thread，仅仅只能单继承2.实现Runnable接口（可实现内部资源共享），接口可以多实现3.经典问题：窗口卖票 2.实例化对象3.执行任务4.销毁线程回收资源 思考：当多个资源需要开启线程来处理的时候，我们怎么办？是否一直在重复下面的流程： create -&gt; run -&gt; destroy复制代码我们知道计算机的每次运行都是需要大量的资源消耗，5个线程的操作可能没有影响，5w个呢？ 五万次创建和销毁才有仅仅五万次的执行吗？执行任务可能花费了大量的时间来处理这些创建和销毁。 线程池 特点 1.解决处理器单元内多个线程的执行问题2.减少处理器单元闲置时间3.增加了处理器单元工作时间内的吞吐能力（为什么这么说？我们减少了多个任务每次线程的创建和销毁浪费，提高了任务执行效率） 组成 1.线程池管理器（ThreadPool）：负责创建、管理、销毁线程池，以及添加任务2.工作线程（PoolWorker）：无任务则等待，可循环、重复执行任务3.任务接口（Task）：每个任务必须实现接口，工作线程负责调度任务的执行，规定了任务的入口，以及任务完成后的收尾工作以及任务执行状态等等4.任务队列（TaskQueue）：存放没有处理的任务，提供任务缓冲机制 eg：超市结账：收营员服务组，单个收营员，收银工作，等待被收银的人群JDK线程池类：java.util.concurrent.Executors和JDK线程池执行器接口：java.util.concurrent.Executor在Executors中，jdk提供了一下相关的线程池，如下： 静态方法创建的线程池类型返回值的实际实现 newFixedThreadPool(int)固定线程池ThreadPoolExecutor newWorkStealingPool()处理器核心数的并行线程池ForkJoinPool newSingleThreadExecutor()一个线程的单独线程池FinalizableDelegatedExecutorService newCachedThreadPool()缓存线程池ThreadPoolExecutor newSingleThreadScheduledExecutor()单独线程定时线程池DelegatedScheduledExecutorService newScheduledThreadPool(int)定时线程池ScheduledThreadPoolExecutor newSingleThreadExecutor() 一个线程的线程池 为什么这里我要拿一个线程的线程池来说明呢？其实我们把简单的搞定复杂的也是演变过来的。先上码：public static ExecutorService newSingleThreadExecutor() { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue()));} public static ExecutorService newSingleThreadExecutor(ThreadFactory threadFactory) { return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue(), threadFactory));}复制代码我们可以看到上面方法的返回值都是ExecutorService，但实际上实例化的是FinalizableDelegatedExecutorService，我们进去看看源码，如下：static class FinalizableDelegatedExecutorService extends DelegatedExecutorService { //构造方法 FinalizableDelegatedExecutorService(ExecutorService executor) { super(executor); } //对象销毁的时候调用 protected void finalize() { super.shutdown(); } }复制代码上面的代码我们可以明显的看到FinalizableDelegatedExecutorService仅仅是对DelegatedExecutorService的封装，唯一实现的就是在对象销毁的时候将ExecutorService结束。到这里我们就应该返回来分析DelegatedExecutorService，以及上面的方法中的具体代码。我们看看默认的单线程线程池的实现，如下：new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue()));//此处的代码实现了一个ExecutorService，分别有几个参数？何解？ //public class ThreadPoolExecutor extends AbstractExecutorService { public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue) { this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue, Executors.defaultThreadFactory(), defaultHandler); }}//我们可以看到几个参数的字面意思分别是：//corePoolSize 核心线程数量，包括空闲线程//maximumPoolSize 最大线程数量//keepAliveTime 保持活跃时间（参照后续源码，这里应该是：当线程数大于核心时，此为终止前多余的空闲线程等待新任务的最长时间）//unit keepAliveTime 参数的时间单位//workQueue 执行前用于保持任务的队列。此队列仅保持由 execute方法提交的 Runnable任务//Executors.defaultThreadFactory() 默认线程工厂//defaultHandler 超出线程和任务队列的任务的处理程序，实现为：new AbortPolicy()，当然这里默认是没有处理的，需要我们手动实现 //这里，我们接着看默认的线程工厂，毕竟线程池核心是需要线程来执行任务，所以此处先看线程来源。static class DefaultThreadFactory implements ThreadFactory { //池数量，指定原子操作 private static final AtomicInteger poolNumber = new AtomicInteger(1); //线程组 private final ThreadGroup group; //线程数量，指定原子操作 private final AtomicInteger threadNumber = new AtomicInteger(1); //线程名称前缀 private final String namePrefix; DefaultThreadFactory() { //获取系统安全管理器 SecurityManager s = System.getSecurityManager(); //创建线程组，由是否获取系统安全管理器决定 group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); //构造线程名称 namePrefix = &quot;pool-&quot; + poolNumber.getAndIncrement() + &quot;-thread-&quot;; } //创建线程 public Thread newThread(Runnable r) { //将线程组、Runnable接口（线程实际执行代码块）、线程名、线程所需要的堆栈大小为0 Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(), 0); //如果为守护线程，取消守护状态，必须在线程执行前调用这个setDaemon方法 if (t.isDaemon()) t.setDaemon(false); //默认任务优先级，值为5 if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; } }//上面的默认线程工厂，提供给了我们一个非守护线程的线程，由原子操作保证线程唯一，任务优先级默认（最低1，最高10，默认5，此处优先级为5） 复制代码看了上面这些我们可以总结一下：单线程线程池，默认只有一个线程和一个线程池，等待新任务时间为0，添加了原子操作来绑定线程。是不是到这里就完了？ 当然没有，我们现在需要看看更加具体的ThreadPoolExecutor，才能更加深入明白线程池。public class ThreadPoolExecutor extends AbstractExecutorService { /* 所有的构造方法均指向这里，所以我们看一下这个就足够 */ public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { //参数检查，说明线程池不能线程=0，也不能最大线程数量不大于0切最大线程数量不能少于核心线程数量，等待任务最长时间不能小于0 if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); //等待任务队列、线程工厂、超任务队列的处理程序 if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); //上面的判断，可以看做是一种防御式编程，所有的问题预先处理，后续无需考虑类似问题 //构造线程池相关设定阈值 this.acc = System.getSecurityManager() == null ? null : AccessController.getContext(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; }} //到了这里其实我们不必先追究具体的实现，还是先看看AbstractExecutorService吧。 //抽象的执行服务public abstract class AbstractExecutorService implements ExecutorService { //执行方法 private &lt;T&gt; T doInvokeAny(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, boolean timed, long nanos) throws InterruptedException, ExecutionException, TimeoutException { if (tasks == null) throw new NullPointerException(); //获取任务数量 int ntasks = tasks.size(); if (ntasks == 0) throw new IllegalArgumentException(); //任务集合 ArrayList&lt;Future&lt;T&gt;&gt; futures = new ArrayList&lt;Future&lt;T&gt;&gt;(ntasks); //执行完成服务 ExecutorCompletionService&lt;T&gt; ecs = new ExecutorCompletionService&lt;T&gt;(this); try { // 记录异常 ExecutionException ee = null; //超时时间线 final long deadline = timed ? System.nanoTime() + nanos : 0L; //使用迭代器获取任务 Iterator&lt;? extends Callable&lt;T&gt;&gt; it = tasks.iterator(); // 确定开始一项任务 futures.add(ecs.submit(it.next())); //任务数量减少 --ntasks; //正在执行任务标志 int active = 1; //循环执行任务 for (;;) { //获取任务队列中第一个任务 Future&lt;T&gt; f = ecs.poll(); //任务为空，如果还有任务则执行任务（任务数量减1，提交任务到执行队列，正在执行任务数量+1） //正在执行任务数为0，说明任务执行完毕，中断任务循环 //若有超时检查，则执行超时检查机制 //上述情况都不满足，则取出任务队列头，并将其从队列移除 if (f == null) { if (ntasks &gt; 0) { --ntasks; futures.add(ecs.submit(it.next())); ++active; } else if (active == 0) break; else if (timed) { f = ecs.poll(nanos, TimeUnit.NANOSECONDS); if (f == null) throw new TimeoutException(); nanos = deadline - System.nanoTime(); } else f = ecs.take(); } //任务不为空 if (f != null) { //正在执行标志-1 --active; try { //返回执行结果 return f.get(); } catch (ExecutionException eex) { ee = eex; } catch (RuntimeException rex) { ee = new ExecutionException(rex); } } } if (ee == null) ee = new ExecutionException(); throw ee; } finally { //取消所有任务 for (int i = 0, size = futures.size(); i &lt; size; i++) futures.get(i).cancel(true); } } //执行方法 public &lt;T&gt; List&lt;Future&lt;T&gt;&gt; invokeAll(Collection&lt;? extends Callable&lt;T&gt;&gt; tasks, long timeout, TimeUnit unit) throws InterruptedException { if (tasks == null) throw new NullPointerException(); long nanos = unit.toNanos(timeout); //和上面类似，这里也是创建任务队列 ArrayList&lt;Future&lt;T&gt;&gt; futures = new ArrayList&lt;Future&lt;T&gt;&gt;(tasks.size()); boolean done = false; //迭代进行任务执行 try { //创建任务，并添加到任务队列 for (Callable&lt;T&gt; t : tasks) futures.add(newTaskFor(t)); //设置超时时间标记 final long deadline = System.nanoTime() + nanos; final int size = futures.size(); //在执行器没有多少多并行性的情况下，交替执行时间检查和调用。 for (int i = 0; i &lt; size; i++) { execute((Runnable)futures.get(i)); nanos = deadline - System.nanoTime(); //任务超时，返回任务队列 if (nanos &lt;= 0L) return futures; } //遍历任务并返回任务执行结果 for (int i = 0; i &lt; size; i++) { Future&lt;T&gt; f = futures.get(i); if (!f.isDone()) { //超时 if (nanos &lt;= 0L) return futures; try { //给定执行时间等待任务完成并返回结果 f.get(nanos, TimeUnit.NANOSECONDS); } catch (CancellationException ignore) { } catch (ExecutionException ignore) { } catch (TimeoutException toe) { return futures; } nanos = deadline - System.nanoTime(); } } done = true; return futures; } finally { //未完成则取消执行 if (!done) for (int i = 0, size = futures.size(); i &lt; size; i++) futures.get(i).cancel(true); } } /** *创建任务队列 */ protected &lt;T&gt; RunnableFuture&lt;T&gt; newTaskFor(Runnable runnable, T value) { return new FutureTask&lt;T&gt;(runnable, value); } /** * 提交任务到执行队列 */ public Future&lt;?&gt; submit(Runnable task) { if (task == null) throw new NullPointerException(); RunnableFuture&lt;Void&gt; ftask = newTaskFor(task, null); execute(ftask); return ftask; } }复制代码通过上面的代码我们已经基本了解了一个线程池是如何创建任务队列并执行任务的，所以在这里我们只需要关注一些关键的ThreadPoolExecutor的方法就能了解线程池是如何工作的，并且对应的几种模式的线程池都可以推导出来。首先在这次看源码之前我们要胡乱思索一番，整理一下线程池的执行大概流程： 我们前面简单的说过几个ThreadPoolExecutor的主要参数，我们下面再仔细总结一下：public class ThreadPoolExecutor extends AbstractExecutorService { public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) { if (corePoolSize &lt; 0 || maximumPoolSize &lt;= 0 || maximumPoolSize &lt; corePoolSize || keepAliveTime &lt; 0) throw new IllegalArgumentException(); if (workQueue == null || threadFactory == null || handler == null) throw new NullPointerException(); this.corePoolSize = corePoolSize; this.maximumPoolSize = maximumPoolSize; this.workQueue = workQueue; this.keepAliveTime = unit.toNanos(keepAliveTime); this.threadFactory = threadFactory; this.handler = handler; } }复制代码corePoolSize：该线程池中核心线程数最大值 核心线程：线程池新建线程的时候，如果当前线程总数小于corePoolSize，则新建的是核心线程，如果超过corePoolSize，则新建的线程不是核心线程。核心线程默认情况下会一直存活在线程池中，即使这个核心线程啥也不干(闲置状态)。如果指定ThreadPoolExecutor的allowCoreThreadTimeOut这个属性为true，那么核心线程如果不干活(闲置状态)的话，超过一定时间(时长下面参数决定)，就会被销毁掉。 maximumPoolSize： 该线程池中线程总数最大值 线程总数 = 核心线程数 + 非核心线程数。 keepAliveTime：该线程池中非核心线程闲置超时时长 一个非核心线程，如果不干活(闲置状态)的时长超过这个参数所设定的时长，就会被销毁掉，如果设置allowCoreThreadTimeOut = true，则会作用于核心线程。 unit：keepAliveTime的单位 TimeUnit是一个枚举类型，其包括：NANOSECONDS ： 1微毫秒 = 1微秒 / 1000MICROSECONDS ： 1微秒 = 1毫秒 / 1000MILLISECONDS ： 1毫秒 = 1秒 /1000SECONDS ： 秒MINUTES ： 分HOURS ： 小时DAYS ： 天 workQueue：线程池中的任务队列：维护着等待执行的Runnable对象 当所有的核心线程都在干活时，新添加的任务会被添加到这个队列中等待处理，如果队列满了，则新建非核心线程执行任务。 threadFactory：创建线程的方式。 handler：异常处理程序。 既然已经知道了任务执行，那么任务是怎么排队的呢？public void execute(Runnable command) { if (command == null) throw new NullPointerException(); /* * 1. 如果运行的线程少于corepoolSize大小，新任务会直接开启新的线程执行。 * 对addWorker的调用原子性地检查运行状态和workerCount，从而通过返回false防止假警报，假警报会在不应该的情况下添加线程。 * * 2. 如果一个任务成功的加入队列，我们需要再次检查是否需要开启新的线程来执行。 * 可能原因有：已有任务执行完毕，或者线程池已经被结束。 * * * 3. 如果不能对任务进行排队，则尝试添加一个新任务线程。 * 如果它失败了，我们知道我们已经关闭或饱和了所以拒绝这个任务。 */ //运行状态标签 int c = ctl.get(); //正在执行的线程数 &lt; 核心线程数 ，则立即执行任务 if (workerCountOf(c) &lt; corePoolSize) { if (addWorker(command, true)) return; c = ctl.get(); } //再次检查是否运行且没超过任务队列容量 if (isRunning(c) &amp;&amp; workQueue.offer(command)) { int recheck = ctl.get(); //需要执行的任务不在运行状态且不在等待队列，则将这个任务异常抛出 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); //运行任务数量为空，则将核心线程外的线程任务置空 else if (workerCountOf(recheck) == 0) addWorker(null, false); } //超过核心线程数且其他线程任务也添加失败，抛出异常 else if (!addWorker(command, false)) reject(command); } 复制代码看到这里我们已经模模糊糊的明白了任务排队执行，所有的任务队列都是一样的排队执行，那么我们任务队列又有哪些呢？ LinkedBlockingQueue：线性阻塞队列。接收到任务，如果没超过corePoolSize，则创建新线程执行，否则进入阻塞队列等待 ArrayBlockingQueue：数组阻塞队列。数组特诊是长度固定，也就是这个队列长度固定。接收到新任务，如果没超过corePoolSize，则创建新线程执行，如果超过，则创建新线程（线程总数&lt;maximumPoolSize）执行。如果新任务既不能在队列中等待，又不能执行，抛出异常。 SynchronousQueue：同步队列。 既然是同步队列，说明新任务来了就执行。也就是核心线程数量无限大。 DelayQueue：延迟队列，听名字也知道任务要延迟执行，这个队列接收到任务时，首先先入队，只有达到了指定的延时时间，才会执行任务。 也就是说到了这里，我们基本已经分析了线程池的几个核心：jdk自带线程池种类、线程池内的线程工厂（用于生产线程）、线程池任务执行、线程池任务排队、线程池队列类型。我们总结一张图，可以结束本篇文章，当然其他类型的线程池具体实现，请自行查看源码。 思考：在Java开发中还有哪些类似的东西是这种操作的呢？ 作者：pc859107393链接：https://juejin.im/post/5ba28fb36fb9a05d2c43a57a来源：掘金著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[{"name":"线程池","slug":"线程池","permalink":"http://yoursite.com/categories/线程池/"}],"tags":[{"name":"线程池","slug":"线程池","permalink":"http://yoursite.com/tags/线程池/"}]},{"title":"通过面试题，让我们来了解Collection","slug":"通过面试题，让我们来了解Collection","date":"2019-02-25T16:00:00.000Z","updated":"2019-03-26T08:31:43.504Z","comments":true,"path":"2019/02/26/通过面试题，让我们来了解Collection/","link":"","permalink":"http://yoursite.com/2019/02/26/通过面试题，让我们来了解Collection/","excerpt":"","text":"前言本章主要介绍Collection集合相关知识，结合面试中会提到的相关问题进行知识点的梳理。希望能帮到大家~ 基于JDK1.8，如有错误，还望大家能够指出！ 涉及的Collection集合相关面试题 1.什么是集合？ 2.AVA中集合类型都有哪些？有什么特点？ 3.说一说集合的父类Collection？ 4.数组和集合都有哪些区别？ 5.说一说迭代器Iterator 6.Collection接口中几种重要的类和接口简介 1.什么是集合？来自百度百科的回答： 12345集合类存放于java.util包中。集合类存放的都是对象的引用，而非对象本身，出于表达上的便利，我们称集合中的对象就是指集合中对象的引用（reference)。集合类型主要有3种：set(集）、list(列表）和map(映射)。集合接口分为：Collection和Map，list、set实现了Collection接口 2.JAVA中集合类型都有哪些？各有什么特点？Collection两大体系：链表List、集合SetList特点：元素有序；元素可以重复；元素都有索引（角标） List里存放的对象是有序的，同时也是可以重复的，List关注的是索引，拥有一系列和索引相关的方法，查询速度快。因为往list集合里插入或删除数据时，会伴随着后面数据的移动，所有插入删除数据速度慢。 Set特点：元素无序；元素不可以重复； Set里存放的对象是无序，不能重复的，集合中的对象不按特定的方式排序，只是简单地把对象加入集合中。 同时集合中还有另外一种类型：Map(映射)。 Map特点：键值对；键不可以重复；值可以重复； Map集合中存储的是键值对，键不能重复，值可以重复。根据键得到值，对map集合遍历时先得到键的set集合，对set集合进行遍历，得到相应的值。 3.说一说集合的父类Collection？3.1 Collection 体系结构图 CollectionList:有序集合，允许相同元素和null） –LinkedList （非同步，允许相同元素和null，遍历效率低插入和删除效率高） –ArrayList （非同步，允许相同元素和null，实现了动态大小的数组，遍历效率高，用的多） –Vector（同步，允许相同元素和null，效率低） —Stack（继承自Vector，实现一个后进先出的堆栈Set （无序集合，不允许相同元素，最多有一个null元素） –HashSet(无序集合，不允许相同元素，最多有一个null元素) Map （没有实现collection接口，key不能重复，value可以重复，一个key映射一个value） –Hashtable （实现Map接口，同步，不允许null作为key和value，用自定义的类当作key的话要复写hashCode和eques方法，） –HashMap （实现Map接口，非同步，允许null作为key和value，用的多） –WeakHashMap（实现Map接口） 3.2 Collection 中的主要方法（1）添加boolean add(E o);boolean add(Collection&lt;? extends E&gt; c); （2）删除boolean remove(Object o);boolean removeAll(Collection&lt;? extends E&gt; c)void clear()； （3）判断 a.判断集合中是否有元素：boolean isEmpty();b.判断集合中是否包含某个元素：boolean contains(Object o);c.判断集合中是否包含某些元素：boolean contains(Collection&lt;?&gt; c); （4）获取a.获取集合中元素个数：int size();b.遍历集合中所有元素：Iterator iterator();c.判断两个集合中是否存在相同的元素并保留两个集合中相同的元素删除不同的元素：boolean retainAll(Collection&lt;?&gt; c); （5）其他将集合中元素转为数组: a. Ojbect[] toArray();b. T[] toArray(); 泛型Java8新增方法：在 JDK 8 以后，Collection 接口还提供了从集合获取连续的或者并行流：Stream stream()Stream parallelStream()于Collection接口相关还有一个抽象类AbstractCollection：AbstractCollection是一个抽象类，实现了Collection接口的部分功能，实现了一些最基本的通用操作，把复杂的和业务相关的延迟到子类实现。在AbstractCollection中，主要实现了contains(), isEmpty(), toArray(), remove(), clear() 这几个操作。有兴趣的同学可以自行研究下，逻辑都比较简单。特别注意：List接口扩展了一个一些方法，其中最重要，也是用的最多的是：E get(int index) 返回指定索引的元素 4.数组和集合都有哪些区别？数组特点： 1.数组本质上就是一段连续的内存空间，用于记录多个类型相同的数据；2.数据一旦声明完毕，则内存空间固定不变；3.插入和删除操作不方便，可能会移动大量的元素并导致效率太低；4.支持下标访问，可以实现随机访问；5.数组中的元素可以是基本数据类型，也可以使用引用数据类型。 集合特点： 1.内存空间可以不连续，数据类型可以不相同；2.集合的内存空间可以动态的调整；3.集合的插入删除操作可以不移动大量元素；4.部分支持下标访问，部分不支持；5.集合中的元素必须是引用数据类型(你存储的是简单的int，它会自动装箱成Integer)； 可以看出数组和集合在数据的存储，访问，类型，长度等都有不同的地方。 5.说一说迭代器 Iterator？ （1）通过集合对象获取其对应的Iterator对象 （2）判断是否存在下一个元素 （3）取出该元素并将迭代器对象指向下一个元素 Iterator iterator():取出元素的方式：迭代器。 1234该对象必须依赖于具体容器，因为每一个容器的数据结构都不同。所以该迭代器对象是在容器中进行内部实现的。对于使用容器者而言，具体的实现不重要，只要通过容器获取到该实现的迭代器的对象即可，也就是iterator方法。 扩展知识：ArrayList里面的iterator方法采用了设计模式中的——工厂方法模式！有兴趣的同学可以后续看到我另外的文章“设计模式精讲”专栏。 6.Collection接口中几种重要的类和接口简介？该问题与第二个问题类似~ 后续文章会有更详细的介绍！Collection两大体系：链表List、集合Set 另映射Map List接口及子类介绍 List是有序的Collection，使用此接口能够精确的控制每个元素插入的位置。用户能够使用索引（元素在List中的位置，类似于数组下标）来访问List中的元素，这类似于Java的数组。 和下面要提到的Set不同，List允许有相同的元素。 除了具有Collection接口必备的iterator()方法外，List还提供一个listIterator()方法，返回一个ListIterator接口，和标准的Iterator接口相比，ListIterator多了一些add()之类的方法，允许添加，删除，设定元素，还能向前或向后遍历。 实现List接口的常用类有： LinkedList类 （底层数据结构是链表，线程不安全） ArrayList类 （底层数据结构是数组，线程不安全） Vector类 （底层数据结构是数组，线程安全） Stack类 （顾名思义：栈，继承至Vector类并进行扩展）在后续的文章中我们将一一详细介绍这些类的相关特性！ Set接口及子类介绍Set是一种不包含重复的元素的Collection，即任意的两个元素e1和e2都有e1.equals(e2)=false，Set最多有一个null元素。很明显，Set的构造函数有一个约束条件，传入的Collection参数不能包含重复的元素。 注意：必须小心操作可变对象（Mutable Object）。如果一个Set中的可变元素改变了自身状态导致Object.equals(Object)=true将导致一些问题。实现Set接口的常用类有： HashSet类 （底层数据结构是数组+单链表+红黑树，无序） LinkedHashSet （底层数据结构是数组+单链表+红黑树+双向链表，无序） TreeSet类 （底层数据结构红黑树，有序）在后续的文章中我们将一一详细介绍这些类的相关特性！ Map接口及子类介绍 注意：Map没有继承Collection接口，Map提供key到value的映射。一个Map中不能包含相同的key，每个key只能映射一个value。Map接口提供3种集合的视图，Map的内容可以被当作一组key集合，一组value集合，或者一组key-value映射。 Hashtable类 HashMap类 在后续的文章中我们将一一详细介绍这些类的相关特性！ 文末本章节介绍了Collection接口中的大部分可能在面试过程中会出现的内容，并没有详细去介绍其子类及其实现相关的原理。这方面的内容会放在后续的章节中去详细介绍。 作者：Coder编程 链接：https://juejin.im/post/5c91df2fe51d454b5c53a335 来源：掘金 著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。","categories":[{"name":"Collection","slug":"Collection","permalink":"http://yoursite.com/categories/Collection/"}],"tags":[{"name":"Collection","slug":"Collection","permalink":"http://yoursite.com/tags/Collection/"}]}]}